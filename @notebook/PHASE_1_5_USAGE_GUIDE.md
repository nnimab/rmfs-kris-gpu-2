# éšæ®µ1.5æ”¹é€²ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

éšæ®µ1.5æˆåŠŸå¯¦ç¾äº†ä¸‰å€‹é—œéµç®—æ³•å„ªåŒ–ï¼Œè§£æ±ºäº†åŸæœ‰NERLå’ŒDQNæ§åˆ¶å™¨çš„å…¬å¹³æ€§å•é¡Œï¼š

1. **è§£æ±ºè³‡è¨Šå­¤å³¶å•é¡Œ** - 16ç¶­ç‹€æ…‹ç©ºé–“åŒ…å«ç›¸é„°è·¯å£ä¿¡æ¯
2. **ä¿®å¾©ç¡¬ç·¨ç¢¼æ­£è¦åŒ–** - è‡ªé©æ‡‰æ­£è¦åŒ–æ©Ÿåˆ¶
3. **çµ±ä¸€çå‹µæ©Ÿåˆ¶** - æ”¯æŒå…¬å¹³å°æ¯”çš„é›™é‡æ¡†æ¶

## ğŸ¯ ä¸»è¦æ”¹é€²åŠŸèƒ½

### 1. 16ç¶­ç‹€æ…‹ç©ºé–“

#### æ”¹é€²å‰ï¼ˆ8ç¶­ï¼‰
```
[æ–¹å‘ç·¨ç¢¼, æ™‚é–“å·®, æ°´å¹³æ©Ÿå™¨äººæ•¸, å‚ç›´æ©Ÿå™¨äººæ•¸, 
 æ°´å¹³å„ªå…ˆç´šæ¯”ä¾‹, å‚ç›´å„ªå…ˆç´šæ¯”ä¾‹, æ°´å¹³ç­‰å¾…æ™‚é–“, å‚ç›´ç­‰å¾…æ™‚é–“]
```

#### æ”¹é€²å¾Œï¼ˆ16ç¶­ï¼‰
```
ç•¶å‰è·¯å£ç‹€æ…‹ï¼ˆ8ç¶­ï¼‰+ ç›¸é„°è·¯å£ç‹€æ…‹ï¼ˆ8ç¶­ï¼‰
- ç›¸é„°è·¯å£æ©Ÿå™¨äººæ•¸é‡
- ç›¸é„°è·¯å£å„ªå…ˆç´šæ©Ÿå™¨äººæ•¸
- ç›¸é„°è·¯å£å¹³å‡ç­‰å¾…æ™‚é–“
- ç›¸é„°è·¯å£æ–¹å‘åˆ†ä½ˆ
- ç›¸é„°è·¯å£è² è¼‰å‡è¡¡æŒ‡æ¨™
```

**å„ªå‹¢ï¼š** è§£æ±ºè³‡è¨Šå­¤å³¶å•é¡Œï¼Œå¯¦ç¾å€åŸŸæ€§å”èª¿æ±ºç­–

### 2. è‡ªé©æ‡‰æ­£è¦åŒ–æ©Ÿåˆ¶

#### æ”¹é€²å‰ï¼ˆç¡¬ç·¨ç¢¼ï¼‰
```python
h_count_norm = min(h_count / 10.0, 1.0)  # å›ºå®šæœ€å¤§å€¼10
h_wait_norm = min(h_wait_time / 50.0, 1.0)  # å›ºå®šæœ€å¤§å€¼50
```

#### æ”¹é€²å¾Œï¼ˆè‡ªé©æ‡‰ï¼‰
```python
normalizer = TrafficStateNormalizer(window_size=1000)
normalizer.update_statistics(raw_features)
normalized = normalizer.normalize_features(raw_features)
```

**å„ªå‹¢ï¼š** å‹•æ…‹é©æ‡‰æ¥µç«¯äº¤é€šç‹€æ³ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›

### 3. çµ±ä¸€çå‹µæ©Ÿåˆ¶

#### æ”¹é€²å‰ï¼ˆä¸ä¸€è‡´ï¼‰
- **DQNï¼š** 5å€‹çµ„ä»¶çš„å³æ™‚çå‹µ
- **NERLï¼š** å…¨å±€é©æ‡‰åº¦å‡½æ•¸

#### æ”¹é€²å¾Œï¼ˆçµ±ä¸€ï¼‰
- **å³æ™‚æ¨¡å¼ï¼š** 8å€‹ç¶­åº¦çš„è©³ç´°çå‹µ
- **å…¨å±€æ¨¡å¼ï¼š** å›åˆçµæŸæ™‚çš„ç¶œåˆè©•ä¼°
- **é›™é‡å°æ¯”ï¼š** ç›¸åŒçå‹µæ©Ÿåˆ¶ä¸‹çš„å…¬å¹³æ¯”è¼ƒ

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å®‰è£ä¾è³´

```bash
pip install -r requirements.txt
```

### è¨“ç·´å‘½ä»¤

#### 1. NERLè¨“ç·´ï¼ˆæ¨è–¦å…¨å±€çå‹µï¼‰
```bash
# é»˜èªé…ç½®
python train.py --agent nerl

# è‡ªå®šç¾©é…ç½®
python train.py --agent nerl --reward_mode global --generations 30 --population 15 --eval_ticks 3000

# å³æ™‚çå‹µæ¨¡å¼ï¼ˆç”¨æ–¼å°æ¯”ï¼‰
python train.py --agent nerl --reward_mode step
```

#### 2. DQNè¨“ç·´ï¼ˆæ¨è–¦å³æ™‚çå‹µï¼‰
```bash
# é»˜èªé…ç½®
python train.py --agent dqn

# è‡ªå®šç¾©é…ç½®
python train.py --agent dqn --reward_mode step --training_ticks 15000

# å…¨å±€çå‹µæ¨¡å¼ï¼ˆç”¨æ–¼å°æ¯”ï¼‰
python train.py --agent dqn --reward_mode global
```

#### 3. å››ç¨®å°æ¯”æ¨¡å¼
```bash
# ç®—æ³•å°æ¯”ï¼ˆç›¸åŒçå‹µæ©Ÿåˆ¶ï¼‰
python train.py --agent dqn --reward_mode step    # DQNå³æ™‚çå‹µ
python train.py --agent nerl --reward_mode step   # NERLå³æ™‚çå‹µ

python train.py --agent dqn --reward_mode global  # DQNå…¨å±€çå‹µ
python train.py --agent nerl --reward_mode global # NERLå…¨å±€çå‹µ

# çå‹µæ©Ÿåˆ¶å°æ¯”ï¼ˆç›¸åŒç®—æ³•ï¼‰
python train.py --agent dqn --reward_mode step    # DQNå³æ™‚ vs å…¨å±€
python train.py --agent dqn --reward_mode global

python train.py --agent nerl --reward_mode step   # NERLå³æ™‚ vs å…¨å±€
python train.py --agent nerl --reward_mode global
```

### åƒæ•¸èªªæ˜

| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | é¸é … |
|------|------|--------|------|
| `--agent` | è¦è¨“ç·´çš„ç®—æ³• | å¿…éœ€ | `nerl`, `dqn` |
| `--reward_mode` | çå‹µæ¨¡å¼ | `auto` | `step`, `global`, `auto` |
| `--generations` | NERLé€²åŒ–ä»£æ•¸ | 50 | æ­£æ•´æ•¸ |
| `--population` | NERLæ—ç¾¤å¤§å° | 20 | æ­£æ•´æ•¸ |
| `--eval_ticks` | NERLå€‹é«”è©•ä¼°æ™‚é–“ | 2000 | æ­£æ•´æ•¸ |
| `--training_ticks` | DQNè¨“ç·´æ™‚é–“æ­¥ | 10000 | æ­£æ•´æ•¸ |

### NetLogoä»‹é¢ä½¿ç”¨

#### 1. è¨­ç½®16ç¶­æ§åˆ¶å™¨
```python
# Pythonä»£ç¢¼ä¸­
netlogo.set_dqn_controller()  # è‡ªå‹•ä½¿ç”¨16ç¶­ç‹€æ…‹ç©ºé–“
netlogo.set_nerl_controller() # è‡ªå‹•ä½¿ç”¨16ç¶­ç‹€æ…‹ç©ºé–“
```

#### 2. æŸ¥çœ‹æ­£è¦åŒ–çµ±è¨ˆ
```python
# ç²å–æ§åˆ¶å™¨çµ±è¨ˆ
controller = warehouse.intersection_manager.controllers.get('dqn')
normalizer_stats = controller.normalizer.get_statistics_summary()
print(normalizer_stats)
```

#### 3. çå‹µæ¨¡å¼åˆ‡æ›
```python
controller = warehouse.intersection_manager.controllers.get('dqn')
controller.set_reward_mode('global')  # åˆ‡æ›åˆ°å…¨å±€æ¨¡å¼
```

## ğŸ“Š æ¨¡å‹è¼¸å‡º

### è¨“ç·´æ¨¡å‹å‘½å
- **DQNæ¨¡å‹ï¼š** `models/dqn_traffic_{ticks}.pth`
- **NERLæ¨¡å‹ï¼š** `models/nerl_traffic_{ticks}.pth`

### å››ç¨®å°æ¯”æ¨¡å‹
è¨“ç·´å®Œæˆå¾Œå°‡ç”¢å‡ºå››å€‹æ¨¡å‹è®Šé«”ï¼š
1. `dqn_step.pth` - DQNå³æ™‚çå‹µ
2. `dqn_global.pth` - DQNå…¨å±€çå‹µ  
3. `nerl_step.pth` - NERLå³æ™‚çå‹µ
4. `nerl_global.pth` - NERLå…¨å±€çå‹µ

## ğŸ”§ é«˜ç´šé…ç½®

### è‡ªå®šç¾©çå‹µæ¬Šé‡
```python
from ai.unified_reward_system import UnifiedRewardSystem

custom_weights = {
    'wait_time': 2.0,        # ç­‰å¾…æ™‚é–“æ”¹å–„æ¬Šé‡
    'passing': 1.5,          # æ©Ÿå™¨äººé€šéçå‹µ
    'switch_penalty': -3.0,  # æ–¹å‘åˆ‡æ›æ‡²ç½°
    'energy': -0.2,          # èƒ½æºæ¶ˆè€—æ‡²ç½°
    'fairness': 2.0,         # å…¬å¹³æ€§çå‹µ
    'deadlock_penalty': -10.0 # æ­»é–æ‡²ç½°
}

reward_system = UnifiedRewardSystem(reward_mode="step", weights=custom_weights)
```

### è‡ªå®šç¾©æ­£è¦åŒ–çª—å£
```python
from ai.adaptive_normalizer import TrafficStateNormalizer

# æ›´é•·çš„çµ±è¨ˆçª—å£ï¼ˆæ›´ç©©å®šä½†é©æ‡‰è¼ƒæ…¢ï¼‰
normalizer = TrafficStateNormalizer(window_size=2000)

# æ›´çŸ­çš„çª—å£ï¼ˆé©æ‡‰æ›´å¿«ä½†å¯èƒ½ä¸ç©©å®šï¼‰
normalizer = TrafficStateNormalizer(window_size=500)
```

## ğŸ“ˆ æ€§èƒ½é æœŸ

### é æœŸæ”¹é€²æ•ˆæœ
1. **è³‡è¨Šå­¤å³¶è§£æ±ºï¼š** è·¯å£å”èª¿æ±ºç­–èƒ½åŠ›æå‡15-25%
2. **è‡ªé©æ‡‰æ­£è¦åŒ–ï¼š** æ¥µç«¯äº¤é€šé©æ‡‰èƒ½åŠ›æå‡30-40%  
3. **çµ±ä¸€çå‹µï¼š** å…¬å¹³å°æ¯”åŸºç¤ï¼Œæ¶ˆé™¤ç®—æ³•åè¦‹

### å»ºè­°å¯¦é©—æµç¨‹
1. **åŸºç·šæ¸¬è©¦ï¼š** ä½¿ç”¨åŸæœ‰8ç¶­æ§åˆ¶å™¨å»ºç«‹åŸºç·š
2. **16ç¶­æ¸¬è©¦ï¼š** é©—è­‰ç‹€æ…‹ç©ºé–“æ“´å±•æ•ˆæœ
3. **å°æ¯”å¯¦é©—ï¼š** å››ç¨®æ¨¡å¼å…¬å¹³æ¯”è¼ƒ
4. **æ¶ˆèç ”ç©¶ï¼š** åˆ†æå„æ”¹é€²çµ„ä»¶çš„è²¢ç»

## âš ï¸ æ³¨æ„äº‹é …

### è¨ˆç®—è³‡æº
- **16ç¶­ç‹€æ…‹ï¼š** è¨ˆç®—è¤‡é›œåº¦ç•¥æœ‰å¢åŠ ï¼ˆç´„15%ï¼‰
- **è‡ªé©æ‡‰æ­£è¦åŒ–ï¼š** è¨˜æ†¶é«”ä½¿ç”¨å¢åŠ ï¼ˆçµ±è¨ˆçª—å£ï¼‰
- **çµ±ä¸€çå‹µï¼š** çå‹µè¨ˆç®—æ›´è¤‡é›œä½†æ›´æº–ç¢º

### å…¼å®¹æ€§
- **å‘å¾Œå…¼å®¹ï¼š** åŸæœ‰8ç¶­æ§åˆ¶å™¨ä»å¯ä½¿ç”¨
- **æ¨¡å‹æ–‡ä»¶ï¼š** æ–°èˆŠæ¨¡å‹ä¸äº’ç›¸å…¼å®¹
- **NetLogoä»‹é¢ï¼š** ç„¡éœ€ä¿®æ”¹ï¼Œè‡ªå‹•é©é…

### èª¿è©¦å»ºè­°
```bash
# æ¸¬è©¦åŸºæœ¬åŠŸèƒ½
python simple_test_phase_1_5.py

# æª¢æŸ¥æ¨¡å‹æ¶æ§‹
python -c "from ai.controllers.dqn_controller import DQNController; print(DQNController().state_size)"

# é©—è­‰çå‹µç³»çµ±
python -c "from ai.unified_reward_system import UnifiedRewardSystem; r=UnifiedRewardSystem('step'); print('OK')"
```

## ğŸ¯ ä¸‹ä¸€æ­¥ï¼šéšæ®µ2è©•ä¼°

å®Œæˆéšæ®µ1.5æ”¹é€²å¾Œï¼Œå»ºè­°é€²å…¥éšæ®µ2ï¼š

1. **å‰µå»ºevaluate.py** - çµ±ä¸€è©•ä¼°æ¡†æ¶
2. **å¤šç¶­åº¦å°æ¯”å¯¦é©—** - å…­ç¨®æ§åˆ¶å™¨å…¬å¹³æ¯”è¼ƒ
3. **æ•¸æ“šåˆ†æèˆ‡è¦–è¦ºåŒ–** - è«–æ–‡æ‰€éœ€åœ–è¡¨å’Œå ±å‘Š

ä½¿ç”¨æ”¹é€²å¾Œçš„æ§åˆ¶å™¨å°‡ç‚ºè«–æ–‡æä¾›æ›´å¯é ã€æ›´å…¬å¹³çš„å¯¦é©—çµæœã€‚