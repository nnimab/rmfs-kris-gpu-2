  2️⃣ NERL 訓練機制

  NERL 的訓練方式確實是每個個體都在全新的環境中評估：

  - 每個世代：評估所有個體（如20個）
  - 每個個體：創建全新的倉庫環境，運行 eval_ticks（如2000 ticks）
  - 不保存環境狀態：每次都是從零開始
  - 公平評估：所有個體面對相同的初始條件

  這與 DQN 不同：
  - DQN：在同一個持續的環境中訓練
  - NERL：每個評估都是獨立的新環境

  這就是為什麼 NERL 訓練時間較長的原因 - 需要為每個個體運行完整的模擬。
  1️⃣ NERL 模型儲存總結

  - 只保存最佳個體（best_individual）
  - 自動保存：找到更好的個體時立即保存
  - 檔案格式：models/nerl_traffic.pth
  - 不保存整個族群，節省空間
  