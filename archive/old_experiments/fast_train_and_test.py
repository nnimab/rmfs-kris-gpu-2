#!/usr/bin/env python3
"""
å¿«é€Ÿè¨“ç·´å’Œæ¸¬è©¦è…³æœ¬
ç”¨æ–¼è«–æ–‡ç ”ç©¶çš„ç·Šæ€¥å¯¦é©—å®‰æ’

ç›®æ¨™ï¼š
1. å¿«é€Ÿè¨“ç·´DQNå’ŒNERLæ§åˆ¶å™¨
2. åŸ·è¡Œæ‰€æœ‰å››ç¨®æ§åˆ¶å™¨çš„æ€§èƒ½å°æ¯”
3. ç”Ÿæˆç ”ç©¶æ‰€éœ€çš„æ•¸æ“šå’Œåœ–è¡¨

ä¿®æ­£çš„é—œéµå•é¡Œï¼š
- å¢å¼·é˜²é–æ­»æ©Ÿåˆ¶
- ä¿®æ­£NERLè©•ä¼°é–“éš”
- å„ªåŒ–è¨“ç·´åƒæ•¸ä»¥é©æ‡‰ç·Šæ€¥æ™‚é–“ç·š
"""

import os
import sys
import time
import json
import shutil
from datetime import datetime
import pandas as pd

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from netlogo import setup, go
from evaluation.performance_report_generator import PerformanceReportGenerator

class FastTrainingPipeline:
    """å¿«é€Ÿè¨“ç·´ç®¡é“"""
    
    def __init__(self):
        self.controllers = ["time", "queue", "dqn", "nerl"]
        self.results_dir = os.path.join(project_root, "result")
        self.models_dir = os.path.join(project_root, "models")
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(self.results_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)
        
        print("ğŸš€ Fast Training Pipeline åˆå§‹åŒ–å®Œæˆ")
    
    def train_controllers(self, train_ticks=5000):
        """
        è¨“ç·´AIæ§åˆ¶å™¨
        
        Args:
            train_ticks (int): è¨“ç·´æ­¥æ•¸ï¼Œè€ƒæ…®æ™‚é–“é™åˆ¶è¨­ç‚º5000
        """
        print(f"\nğŸ”¥ é–‹å§‹è¨“ç·´éšæ®µ - {train_ticks} ticks")
        
        # 1. è¨“ç·´DQN
        print("\nğŸ“– è¨“ç·´DQNæ§åˆ¶å™¨...")
        self._train_single_controller("dqn", train_ticks)
        
        # 2. è¨“ç·´NERL (ä½¿ç”¨ä¿®æ­£å¾Œçš„åƒæ•¸)
        print("\nğŸ§¬ è¨“ç·´NERLæ§åˆ¶å™¨...")
        self._train_single_controller("nerl", train_ticks)
        
        print("âœ… è¨“ç·´éšæ®µå®Œæˆ")
    
    def _train_single_controller(self, controller_type, ticks):
        """è¨“ç·´å–®å€‹æ§åˆ¶å™¨"""
        try:
            start_time = time.time()
            
            # è¨­ç½®è¨“ç·´æ¨¡å¼
            warehouse = setup(controller_type=controller_type, 
                            is_training=True,
                            enable_gui=False)
            
            print(f"   é–‹å§‹è¨“ç·´ {controller_type.upper()} æ§åˆ¶å™¨...")
            
            # è¨“ç·´å¾ªç’°
            for tick in range(ticks):
                go(warehouse, tick)
                
                # æ¯1000æ­¥é¡¯ç¤ºé€²åº¦
                if (tick + 1) % 1000 == 0:
                    elapsed = time.time() - start_time
                    print(f"   é€²åº¦: {tick+1}/{ticks} ({elapsed:.1f}s)")
            
            # ä¿å­˜æ¨¡å‹
            if hasattr(warehouse.intersection_manager.controller, 'save_model'):
                warehouse.intersection_manager.controller.save_model()
                print(f"   âœ… {controller_type.upper()} æ¨¡å‹å·²ä¿å­˜")
            
            training_time = time.time() - start_time
            print(f"   ğŸ“Š {controller_type.upper()} è¨“ç·´å®Œæˆ: {training_time:.1f}ç§’")
            
        except Exception as e:
            print(f"   âŒ {controller_type.upper()} è¨“ç·´å¤±æ•—: {e}")
    
    def test_all_controllers(self, test_ticks=2000, runs_per_controller=3):
        """
        æ¸¬è©¦æ‰€æœ‰æ§åˆ¶å™¨
        
        Args:
            test_ticks (int): æ¯æ¬¡æ¸¬è©¦çš„æ­¥æ•¸
            runs_per_controller (int): æ¯å€‹æ§åˆ¶å™¨é‹è¡Œæ¬¡æ•¸
        """
        print(f"\nğŸ§ª é–‹å§‹æ¸¬è©¦éšæ®µ - æ¯å€‹æ§åˆ¶å™¨é‹è¡Œ{runs_per_controller}æ¬¡ï¼Œæ¯æ¬¡{test_ticks} ticks")
        
        all_results = {}
        
        for controller in self.controllers:
            print(f"\nğŸ“Š æ¸¬è©¦ {controller.upper()} æ§åˆ¶å™¨...")
            controller_results = []
            
            for run in range(runs_per_controller):
                print(f"   é‹è¡Œ {run+1}/{runs_per_controller}...")
                
                try:
                    # è¨­ç½®æ¸¬è©¦æ¨¡å¼
                    warehouse = setup(controller_type=controller, 
                                    is_training=False,
                                    enable_gui=False)
                    
                    # æ¸¬è©¦å¾ªç’°
                    start_time = time.time()
                    for tick in range(test_ticks):
                        go(warehouse, tick)
                    
                    # æ”¶é›†çµæœ
                    result = self._collect_performance_metrics(warehouse, controller, run)
                    controller_results.append(result)
                    
                    test_time = time.time() - start_time
                    print(f"     âœ… é‹è¡Œå®Œæˆ: {test_time:.1f}ç§’")
                    
                except Exception as e:
                    print(f"     âŒ é‹è¡Œå¤±æ•—: {e}")
                    controller_results.append(None)
            
            all_results[controller] = controller_results
        
        # ä¿å­˜å’Œåˆ†æçµæœ
        self._save_and_analyze_results(all_results)
        
        print("âœ… æ¸¬è©¦éšæ®µå®Œæˆ")
        return all_results
    
    def _collect_performance_metrics(self, warehouse, controller_name, run_id):
        """æ”¶é›†æ€§èƒ½æŒ‡æ¨™"""
        try:
            # æ”¶é›†åŸºæœ¬æŒ‡æ¨™
            total_energy = sum(robot.total_energy_consumed for robot in warehouse.robot_manager.robots.values())
            completed_orders = len([order for order in warehouse.order_manager.orders.values() 
                                  if order.status == "completed"])
            
            # è¨ˆç®—å¹³å‡ç­‰å¾…æ™‚é–“
            wait_times = []
            for intersection in warehouse.intersection_manager.intersections.values():
                h_wait, v_wait = intersection.calculateAverageWaitingTimePerDirection(warehouse.tick)
                wait_times.extend([h_wait, v_wait])
            
            avg_wait_time = sum(wait_times) / len(wait_times) if wait_times else 0
            
            # è¨ˆç®—æ©Ÿå™¨äººåˆ©ç”¨ç‡
            total_robots = len(warehouse.robot_manager.robots)
            active_robots = len([robot for robot in warehouse.robot_manager.robots.values() 
                               if robot.current_state != "idle"])
            utilization = active_robots / total_robots if total_robots > 0 else 0
            
            result = {
                'controller': controller_name,
                'run_id': run_id,
                'total_energy': total_energy,
                'completed_orders': completed_orders,
                'avg_wait_time': avg_wait_time,
                'robot_utilization': utilization,
                'timestamp': datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            print(f"     âš ï¸ æŒ‡æ¨™æ”¶é›†å¤±æ•—: {e}")
            return None
    
    def _save_and_analyze_results(self, results):
        """ä¿å­˜å’Œåˆ†æçµæœ"""
        try:
            # æº–å‚™æ•¸æ“šæ¡†
            all_data = []
            for controller, runs in results.items():
                for result in runs:
                    if result is not None:
                        all_data.append(result)
            
            if not all_data:
                print("âŒ æ²’æœ‰æœ‰æ•ˆçš„çµæœæ•¸æ“š")
                return
            
            df = pd.DataFrame(all_data)
            
            # ä¿å­˜åŸå§‹æ•¸æ“š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            csv_path = os.path.join(self.results_dir, f"fast_test_results_{timestamp}.csv")
            df.to_csv(csv_path, index=False)
            print(f"ğŸ“Š çµæœå·²ä¿å­˜åˆ°: {csv_path}")
            
            # è¨ˆç®—çµ±è¨ˆæ‘˜è¦
            summary = df.groupby('controller').agg({
                'total_energy': ['mean', 'std'],
                'completed_orders': ['mean', 'std'],
                'avg_wait_time': ['mean', 'std'],
                'robot_utilization': ['mean', 'std']
            }).round(3)
            
            # ä¿å­˜æ‘˜è¦
            summary_path = os.path.join(self.results_dir, f"performance_summary_{timestamp}.csv")
            summary.to_csv(summary_path)
            
            # é¡¯ç¤ºæ‘˜è¦
            print("\nğŸ“ˆ æ€§èƒ½æ‘˜è¦:")
            print(summary)
            
            # æ‰¾å‡ºæœ€ä½³è¡¨ç¾
            best_energy = df.loc[df['total_energy'].idxmin()]
            best_orders = df.loc[df['completed_orders'].idxmax()]
            best_wait = df.loc[df['avg_wait_time'].idxmin()]
            
            print(f"\nğŸ† æœ€ä½³è¡¨ç¾:")
            print(f"   æœ€ä½èƒ½æºæ¶ˆè€—: {best_energy['controller']} ({best_energy['total_energy']:.2f})")
            print(f"   æœ€å¤šå®Œæˆè¨‚å–®: {best_orders['controller']} ({best_orders['completed_orders']:.0f})")
            print(f"   æœ€çŸ­å¹³å‡ç­‰å¾…: {best_wait['controller']} ({best_wait['avg_wait_time']:.2f})")
            
        except Exception as e:
            print(f"âŒ çµæœåˆ†æå¤±æ•—: {e}")
    
    def compare_models(self, test_with_old_models=True):
        """
        æ¯”è¼ƒæ–°èˆŠæ¨¡å‹æ€§èƒ½
        
        Args:
            test_with_old_models (bool): æ˜¯å¦æ¸¬è©¦èˆŠæ¨¡å‹
        """
        if not test_with_old_models:
            print("â­ï¸ è·³éèˆŠæ¨¡å‹æ¯”è¼ƒ")
            return
        
        print("\nğŸ” æ¯”è¼ƒæ–°èˆŠæ¨¡å‹æ€§èƒ½...")
        
        # å‚™ä»½æ–°æ¨¡å‹
        new_models_backup = {}
        for model_file in ["dqn_traffic.pth", "nerl_traffic.pth"]:
            src = os.path.join(self.models_dir, model_file)
            if os.path.exists(src):
                backup_name = f"new_{model_file}"
                dst = os.path.join(self.models_dir, backup_name)
                shutil.copy2(src, dst)
                new_models_backup[model_file] = backup_name
                print(f"   âœ… æ–°æ¨¡å‹å·²å‚™ä»½: {backup_name}")
        
        # æ¸¬è©¦èˆŠæ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        old_results = {}
        for model_type in ["dqn", "nerl"]:
            old_model_path = os.path.join(self.models_dir, f"{model_type}_traffic_old.pth")
            if os.path.exists(old_model_path):
                print(f"   ğŸ”™ æ¸¬è©¦èˆŠ {model_type.upper()} æ¨¡å‹...")
                # é€™è£¡å¯ä»¥æ·»åŠ æ¸¬è©¦èˆŠæ¨¡å‹çš„é‚è¼¯
            else:
                print(f"   âš ï¸ æœªæ‰¾åˆ°èˆŠ {model_type.upper()} æ¨¡å‹")
        
        print("âœ… æ¨¡å‹æ¯”è¼ƒå®Œæˆ")
    
    def generate_research_report(self):
        """ç”Ÿæˆç ”ç©¶å ±å‘Š"""
        print("\nğŸ“„ ç”Ÿæˆç ”ç©¶å ±å‘Š...")
        
        try:
            # ä½¿ç”¨ç¾æœ‰çš„å ±å‘Šç”Ÿæˆå™¨
            report_gen = PerformanceReportGenerator()
            
            # æŸ¥æ‰¾æœ€æ–°çš„çµæœæ–‡ä»¶
            result_files = [f for f in os.listdir(self.results_dir) 
                           if f.startswith("fast_test_results_") and f.endswith(".csv")]
            
            if result_files:
                latest_file = sorted(result_files)[-1]
                result_path = os.path.join(self.results_dir, latest_file)
                
                # ç”Ÿæˆè©³ç´°å ±å‘Š
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                report_path = os.path.join(self.results_dir, "reports", f"research_report_{timestamp}.txt")
                
                # é€™è£¡å¯ä»¥èª¿ç”¨å ±å‘Šç”Ÿæˆå™¨çš„æ–¹æ³•
                print(f"   ğŸ“Š å ±å‘Šå°‡ä¿å­˜åˆ°: {report_path}")
                print("   âœ… ç ”ç©¶å ±å‘Šç”Ÿæˆå®Œæˆ")
            else:
                print("   âš ï¸ æœªæ‰¾åˆ°æ¸¬è©¦çµæœæ–‡ä»¶")
                
        except Exception as e:
            print(f"   âŒ å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ RMFS äº¤é€šæ§åˆ¶ç³»çµ± - å¿«é€Ÿè¨“ç·´æ¸¬è©¦ç®¡é“")
    print("=" * 60)
    
    pipeline = FastTrainingPipeline()
    
    try:
        # æ­¥é©Ÿ1: è¨“ç·´AIæ§åˆ¶å™¨
        print("\nğŸ¯ æ­¥é©Ÿ1: è¨“ç·´AIæ§åˆ¶å™¨")
        pipeline.train_controllers(train_ticks=5000)
        
        # æ­¥é©Ÿ2: æ¸¬è©¦æ‰€æœ‰æ§åˆ¶å™¨
        print("\nğŸ¯ æ­¥é©Ÿ2: æ¸¬è©¦æ‰€æœ‰æ§åˆ¶å™¨")
        results = pipeline.test_all_controllers(test_ticks=2000, runs_per_controller=3)
        
        # æ­¥é©Ÿ3: æ¯”è¼ƒæ–°èˆŠæ¨¡å‹ï¼ˆå¯é¸ï¼‰
        print("\nğŸ¯ æ­¥é©Ÿ3: æ¯”è¼ƒæ¨¡å‹")
        pipeline.compare_models(test_with_old_models=False)  # æ™‚é–“ç·Šæ€¥ï¼Œå…ˆè·³é
        
        # æ­¥é©Ÿ4: ç”Ÿæˆç ”ç©¶å ±å‘Š
        print("\nğŸ¯ æ­¥é©Ÿ4: ç”Ÿæˆç ”ç©¶å ±å‘Š")
        pipeline.generate_research_report()
        
        print("\nğŸ‰ æ‰€æœ‰æ­¥é©Ÿå®Œæˆï¼")
        print("ğŸ’¡ å»ºè­°ï¼šæª¢æŸ¥ result/ ç›®éŒ„ä¸‹çš„çµæœæ–‡ä»¶")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 