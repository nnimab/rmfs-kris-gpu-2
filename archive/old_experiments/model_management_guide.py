#!/usr/bin/env python3
"""
æ¨¡å‹ç®¡ç†æŒ‡å— - è¼‰å…¥ã€ç¹¼çºŒè¨“ç·´ã€æ•¸æ“šåˆ†æ
"""

import os
import json
import pandas as pd
from datetime import datetime

def analyze_existing_models():
    """åˆ†æç¾æœ‰çš„æ¨¡å‹å’Œè¨“ç·´æ•¸æ“š"""
    
    print("ğŸ” ç¾æœ‰æ¨¡å‹åˆ†æ")
    print("=" * 60)
    
    # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
    models_dir = "models"
    if os.path.exists(models_dir):
        model_files = [f for f in os.listdir(models_dir) if f.endswith('.pth')]
        
        print("ğŸ“ å¯ç”¨æ¨¡å‹:")
        dqn_models = []
        nerl_models = []
        
        for model_file in model_files:
            file_size = os.path.getsize(os.path.join(models_dir, model_file)) / 1024  # KB
            
            if model_file.startswith('dqn_traffic_'):
                tick = model_file.replace('dqn_traffic_', '').replace('.pth', '')
                dqn_models.append({"tick": tick, "file": model_file, "size": file_size})
                
            elif model_file.startswith('nerl_traffic'):
                if '_' in model_file:
                    tick = model_file.replace('nerl_traffic_', '').replace('.pth', '')
                else:
                    tick = "latest"
                nerl_models.append({"tick": tick, "file": model_file, "size": file_size})
        
        # é¡¯ç¤º DQN æ¨¡å‹
        if dqn_models:
            print("\\nğŸ§  DQN æ¨¡å‹:")
            for model in sorted(dqn_models, key=lambda x: int(x["tick"]) if x["tick"].isdigit() else 0):
                print(f"  âœ… Tick {model['tick']:>6}: {model['file']} ({model['size']:.1f} KB)")
        
        # é¡¯ç¤º NERL æ¨¡å‹  
        if nerl_models:
            print("\\nğŸ§¬ NERL æ¨¡å‹:")
            for model in nerl_models:
                print(f"  âœ… Tick {model['tick']:>6}: {model['file']} ({model['size']:.1f} KB)")
                
        return {"dqn": dqn_models, "nerl": nerl_models}
    else:
        print("âŒ æ²’æœ‰æ‰¾åˆ° models ç›®éŒ„")
        return {"dqn": [], "nerl": []}

def analyze_training_data():
    """åˆ†æè¨“ç·´æ•¸æ“šå’Œå ±å‘Š"""
    
    print("\\nğŸ“Š è¨“ç·´æ•¸æ“šåˆ†æ")
    print("=" * 60)
    
    # æª¢æŸ¥æ€§èƒ½ç¸½çµ
    summary_file = "result/reports/performance_summary.csv"
    if os.path.exists(summary_file):
        df = pd.read_csv(summary_file)
        print("ğŸ“ˆ æ€§èƒ½ç¸½çµ (æœ€è¿‘5æ¬¡è¨“ç·´):")
        print(df.tail().to_string(index=False))
        
        # åˆ†ææœ€ä½³æ€§èƒ½
        if len(df) > 0:
            best_energy = df.loc[df['total_energy_consumption'].idxmin()]
            best_orders = df.loc[df['completed_orders_count'].idxmax()]
            
            print("\\nğŸ† æœ€ä½³æ€§èƒ½è¨˜éŒ„:")
            print(f"  æœ€ä½èƒ½è€—: {best_energy['total_energy_consumption']:.2f} (å®Œæˆè¨‚å–®: {best_energy['completed_orders_count']})")
            print(f"  æœ€å¤šè¨‚å–®: {best_orders['completed_orders_count']} (èƒ½è€—: {best_orders['total_energy_consumption']:.2f})")
    
    # æª¢æŸ¥æ™‚é–“åºåˆ—æ•¸æ“š
    time_series_dir = "result/time_series"
    if os.path.exists(time_series_dir):
        ts_files = [f for f in os.listdir(time_series_dir) if f.endswith('.json')]
        if ts_files:
            print(f"\\nğŸ“‹ æ™‚é–“åºåˆ—æ•¸æ“š: {len(ts_files)} å€‹æ–‡ä»¶")
            
            # åˆ†ææœ€æ–°çš„æ™‚é–“åºåˆ—æ–‡ä»¶
            latest_file = max(ts_files, key=lambda x: os.path.getmtime(os.path.join(time_series_dir, x)))
            file_path = os.path.join(time_series_dir, latest_file)
            
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                
                if data:
                    print(f"  ğŸ“„ æœ€æ–°æ–‡ä»¶: {latest_file}")
                    print(f"  ğŸ“Š æ•¸æ“šé»æ•¸: {len(data)}")
                    
                    # åˆ†æè¨“ç·´é€²åº¦
                    if len(data) > 10:
                        recent_data = data[-10:]  # æœ€è¿‘10å€‹æ•¸æ“šé»
                        avg_energy = sum(d.get('total_energy_consumption', 0) for d in recent_data) / len(recent_data)
                        avg_orders = sum(d.get('completed_orders_count', 0) for d in recent_data) / len(recent_data)
                        
                        print(f"  ğŸ“ˆ æœ€è¿‘è¡¨ç¾: å¹³å‡èƒ½è€— {avg_energy:.2f}, å¹³å‡å®Œæˆè¨‚å–® {avg_orders:.1f}")
                        
            except Exception as e:
                print(f"  âŒ ç„¡æ³•è®€å–æ™‚é–“åºåˆ—æ•¸æ“š: {e}")

def recommend_best_model():
    """æ¨è–¦æœ€ä½³çš„æ¨¡å‹ç”¨æ–¼ç¹¼çºŒè¨“ç·´"""
    
    print("\\nğŸ’¡ æ¨¡å‹æ¨è–¦")
    print("=" * 60)
    
    models = analyze_existing_models()
    
    # DQN æ¨è–¦
    if models["dqn"]:
        latest_dqn = max(models["dqn"], key=lambda x: int(x["tick"]) if x["tick"].isdigit() else 0)
        print(f"ğŸ§  DQN æ¨è–¦: è¼‰å…¥ tick {latest_dqn['tick']} çš„æ¨¡å‹")
        print(f"   ç†ç”±: æœ€æ–°è¨“ç·´çš„æ¨¡å‹ï¼ŒåŒ…å«æœ€å¤šçš„å­¸ç¿’ç¶“é©—")
        
        # å¦‚æœæœ‰å¤šå€‹æ¨¡å‹ï¼Œä¹Ÿæ¨è–¦ä¸­é–“çš„
        if len(models["dqn"]) > 1:
            mid_tick = sorted([int(m["tick"]) for m in models["dqn"] if m["tick"].isdigit()])[len(models["dqn"])//2]
            print(f"   æ›¿ä»£é¸æ“‡: tick {mid_tick} (å¦‚æœæœ€æ–°æ¨¡å‹éæ“¬åˆ)")
    
    # NERL æ¨è–¦
    if models["nerl"]:
        print(f"ğŸ§¬ NERL æ¨è–¦: è¼‰å…¥æœ€æ–°çš„ nerl_traffic.pth")
        print(f"   ç†ç”±: NERL é€šå¸¸ä¿å­˜æœ€ä½³å€‹é«”ï¼Œå¯ç›´æ¥ç¹¼çºŒé€²åŒ–")

def create_continue_training_script():
    """å‰µå»ºç¹¼çºŒè¨“ç·´çš„è…³æœ¬"""
    
    print("\\nğŸš€ ç¹¼çºŒè¨“ç·´æŒ‡å—")
    print("=" * 60)
    
    print("æ–¹æ³•1: ä½¿ç”¨ NetLogo ç•Œé¢")
    print("1. æ‰“é–‹ NetLogo")
    print("2. è¨­ç½®æ§åˆ¶å™¨ä¸¦è¼‰å…¥æ¨¡å‹:")
    print("   - DQN: è¨­ç½® model-tick ç‚ºæƒ³è¦çš„æ™‚é–“é» (å¦‚ 10000)")
    print("   - é»æ“Š 'set-dqn-with-model' æŒ‰éˆ•")
    print("   - æˆ–è€… NERL: ç›´æ¥é»æ“Š 'set-nerl-controller'")
    print("3. é–‹å§‹é‹è¡Œ: é»æ“Š 'go' æŒ‰éˆ•")
    
    print("\\næ–¹æ³•2: ä½¿ç”¨ Python è…³æœ¬")
    print("```python")
    print("import netlogo")
    print("")
    print("# è¼‰å…¥ DQN æ¨¡å‹ä¸¦ç¹¼çºŒè¨“ç·´")
    print("netlogo.setup()")
    print("netlogo.set_dqn_controller(exploration_rate=0.3, load_model_tick=10000)")
    print("netlogo.set_dqn_training_mode(is_training=True)")
    print("")
    print("# æˆ–è¼‰å…¥ NERL æ¨¡å‹ä¸¦ç¹¼çºŒè¨“ç·´")
    print("# netlogo.set_nerl_controller()")
    print("# netlogo.set_nerl_training_mode(is_training=True)")
    print("")
    print("# ç¹¼çºŒè¨“ç·´")
    print("for i in range(10000):  # å†è¨“ç·´ 10000 ticks")
    print("    netlogo.tick()")
    print("    if i % 1000 == 0:")
    print("        print(f'Progress: {i}/10000 ticks')")
    print("```")

def create_model_comparison_script():
    """å‰µå»ºæ¨¡å‹æ¯”è¼ƒè…³æœ¬"""
    
    print("\\nğŸ“Š æ¨¡å‹æ¯”è¼ƒæŒ‡å—")
    print("=" * 60)
    
    print("æ¯”è¼ƒä¸åŒæ™‚é–“é»çš„æ¨¡å‹æ€§èƒ½:")
    print("```python")
    print("from training_guide import TrainingGuide")
    print("")
    print("guide = TrainingGuide()")
    print("")
    print("# æ¯”è¼ƒå¤šå€‹ DQN æ¨¡å‹")
    print("models_to_compare = [")
    print("    {'type': 'dqn', 'tick': 5000},")
    print("    {'type': 'dqn', 'tick': 10000},")
    print("    {'type': 'nerl', 'tick': 'latest'}")
    print("]")
    print("")
    print("guide.compare_models(models_to_compare, test_duration=2000)")
    print("```")

def backup_current_models():
    """å‚™ä»½ç•¶å‰æ¨¡å‹"""
    
    print("\\nğŸ’¾ æ¨¡å‹å‚™ä»½å»ºè­°")
    print("=" * 60)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir = f"models_backup_{timestamp}"
    
    print(f"å»ºè­°å‰µå»ºå‚™ä»½ç›®éŒ„: {backup_dir}")
    print("å‚™ä»½å‘½ä»¤:")
    print(f"mkdir {backup_dir}")
    print(f"copy models\\*.pth {backup_dir}\\")
    print(f"copy result\\reports\\performance_summary.csv {backup_dir}\\")
    
    print("\\né€™æ¨£å¯ä»¥:")
    print("âœ… ä¿è­·ç¾æœ‰çš„è¨“ç·´æˆæœ")
    print("âœ… å…è¨±å®‰å…¨åœ°é€²è¡Œæ–°å¯¦é©—")
    print("âœ… æ¯”è¼ƒä¸åŒç‰ˆæœ¬çš„æ¨¡å‹")

if __name__ == "__main__":
    print("ğŸ¯ AI æ¨¡å‹ç®¡ç†å®Œæ•´æŒ‡å—")
    print("=" * 80)
    
    # åˆ†æç¾æœ‰è³‡æº
    models = analyze_existing_models()
    analyze_training_data()
    
    # æä¾›å»ºè­°
    recommend_best_model()
    create_continue_training_script()
    create_model_comparison_script()
    backup_current_models()
    
    print("\\n" + "=" * 80)
    print("ğŸ‰ ä½ æœ‰è±å¯Œçš„è¨“ç·´æ•¸æ“šï¼å¯ä»¥ç«‹å³é–‹å§‹ç¹¼çºŒè¨“ç·´æˆ–é€²è¡Œæ¨¡å‹æ¯”è¼ƒï¼") 