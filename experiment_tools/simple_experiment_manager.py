#!/usr/bin/env python3
"""
RMFS ç°¡æ½”å¯¦é©—ç®¡ç†ç³»çµ±
====================

å°ˆæ³¨æ–¼æ ¸å¿ƒåŠŸèƒ½çš„å¯¦é©—è‡ªå‹•åŒ–ç®¡ç†å·¥å…·
- ğŸ¤– AIæ¨¡å‹è¨“ç·´
- ğŸ“Š æ•ˆèƒ½é©—è­‰  
- ğŸ“ˆ æ•¸æ“šåˆ†æèˆ‡åœ–è¡¨
- ğŸš€ å®Œæ•´å¯¦é©—æµç¨‹
- âš™ï¸ è‡ªå®šç¾©åƒæ•¸è¨­ç½®

ä½œè€…: Claude AI Assistant
ç‰ˆæœ¬: 1.0
æ—¥æœŸ: 2025-07-09
"""

import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

try:
    from experiment_tools.presets import list_presets, get_preset, format_preset_summary
    from experiment_tools.config_manager import ConfigManager
    from experiment_tools.workflow_runner import WorkflowRunner, Colors
    from experiment_tools.auto_parallel_fix import get_fixer
except ImportError as e:
    print(f"âŒ å°å…¥æ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿æ‰€æœ‰ä¾è³´æ–‡ä»¶éƒ½åœ¨æ­£ç¢ºçš„ä½ç½®")
    sys.exit(1)

class SimpleExperimentManager:
    """ç°¡æ½”å¯¦é©—ç®¡ç†å™¨ä¸»é¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        # ç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„å°ˆæ¡ˆæ ¹ç›®éŒ„
        current_file = Path(__file__).parent
        project_root = current_file.parent  # å¾ experiment_tools å¾€ä¸Šä¸€å±¤
        
        self.config_manager = ConfigManager()
        self.workflow_runner = WorkflowRunner(str(project_root))
        self.current_config = {}
        
    def show_banner(self):
        """é¡¯ç¤ºç³»çµ±æ©«å¹…"""
        banner = f"""
{Colors.CYAN}{Colors.BOLD}
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            RMFS å¯¦é©—è‡ªå‹•åŒ–ç³»çµ±                  â•‘
â•‘               Simple Manager v1.0             â•‘
â•‘                                             â•‘
â•‘  ğŸ¤– AIæ¨¡å‹è¨“ç·´                               â•‘
â•‘  ğŸ“Š æ•ˆèƒ½é©—è­‰ (6å€‹æ§åˆ¶å™¨)                      â•‘  
â•‘  ğŸ“ˆ æ•¸æ“šåˆ†æèˆ‡åœ–è¡¨                            â•‘
â•‘  ğŸš€ å®Œæ•´å¯¦é©—æµç¨‹                              â•‘
â•‘  âš™ï¸ è‡ªå®šç¾©åƒæ•¸è¨­ç½®                            â•‘
â•‘                                             â•‘
â•‘  ä½œè€…: Claude AI Assistant                   â•‘
â•‘  æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{Colors.END}"""
        print(banner)
    
    def show_main_menu(self):
        """é¡¯ç¤ºä¸»é¸å–®"""
        print(f"\n{Colors.BLUE}{Colors.BOLD}{'='*50}")
        print("              ä¸»é¸å–®")
        print(f"{'='*50}{Colors.END}")
        
        print(f"\n{Colors.WHITE}[1] ğŸ¤– è¨“ç·´AIæ¨¡å‹{Colors.END}")
        print(f"    - è¨“ç·´ DQN å’Œ NERL æ¨¡å‹")
        
        print(f"\n{Colors.WHITE}[2] ğŸ“Š æ•ˆèƒ½é©—è­‰{Colors.END}")
        print(f"    - æ¸¬è©¦æ‰€æœ‰6å€‹æ§åˆ¶å™¨æ€§èƒ½")
        
        print(f"\n{Colors.WHITE}[3] ğŸ“ˆ æ•¸æ“šåˆ†æèˆ‡åœ–è¡¨{Colors.END}")
        print(f"    - ç”Ÿæˆå·²æœ‰çµæœçš„åœ–è¡¨")
        
        print(f"\n{Colors.WHITE}[4] ğŸš€ å®Œæ•´å¯¦é©—æµç¨‹{Colors.END}")
        print(f"    - è‡ªå‹•åŸ·è¡Œ è¨“ç·´â†’é©—è­‰â†’åˆ†æ")
        
        print(f"\n{Colors.WHITE}[5] âš™ï¸  è‡ªå®šç¾©åƒæ•¸è¨­ç½®{Colors.END}")
        print(f"    - æ‰‹å‹•è¨­ç½®æ‰€æœ‰è¨“ç·´/è©•ä¼°åƒæ•¸")
        
        print(f"\n{Colors.WHITE}[0] é€€å‡º{Colors.END}")
    
    def get_user_choice(self, prompt: str = "è«‹é¸æ“‡", valid_choices: List[str] = None) -> str:
        """ç²å–ç”¨æˆ¶é¸æ“‡"""
        if valid_choices is None:
            valid_choices = ["1", "2", "3", "4", "5", "0"]
        
        while True:
            choice = input(f"\n{Colors.CYAN}{prompt} [{'/'.join(valid_choices)}]: {Colors.END}").strip()
            
            if choice in valid_choices:
                return choice
            else:
                print(f"{Colors.RED}âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥: {', '.join(valid_choices)}{Colors.END}")
    
    def show_preset_menu(self, workflow_type: str) -> str:
        """
        é¡¯ç¤ºé è¨­é…ç½®é¸å–®
        
        Args:
            workflow_type: å·¥ä½œæµç¨‹é¡å‹ ('training', 'evaluation', 'complete')
            
        Returns:
            str: é¸æ“‡çš„é è¨­é…ç½®åç¨±
        """
        title_map = {
            'training': 'è¨“ç·´AIæ¨¡å‹',
            'evaluation': 'æ•ˆèƒ½é©—è­‰', 
            'complete': 'å®Œæ•´å¯¦é©—æµç¨‹'
        }
        
        print(f"\n{Colors.MAGENTA}{Colors.BOLD}{'='*50}")
        print(f"              {title_map.get(workflow_type, 'é¸æ“‡å¯¦é©—å¼·åº¦')}")
        print(f"{'='*50}{Colors.END}")
        
        if workflow_type == 'evaluation':
            print(f"\n{Colors.WHITE}å°‡æ¸¬è©¦ä»¥ä¸‹6å€‹æ§åˆ¶å™¨:{Colors.END}")
            print(f"{Colors.GREEN}âœ“ time_based, queue_based (å‚³çµ±){Colors.END}")
            print(f"{Colors.GREEN}âœ“ dqn_step, dqn_global, nerl_step, nerl_global (AI){Colors.END}")
        
        print(f"\n{Colors.WHITE}é¸æ“‡å¯¦é©—å¼·åº¦:{Colors.END}\n")
        
        # ç²å–é è¨­é…ç½®åˆ—è¡¨
        presets = list_presets()
        choices = []
        
        for i, preset in enumerate(presets, 1):
            choices.append(str(i))
            print(f"{Colors.WHITE}[{i}] {format_preset_summary(preset['key'])}{Colors.END}\n")
        
        print(f"{Colors.WHITE}[{len(presets) + 1}] ğŸ”§ è‡ªå®šç¾©åƒæ•¸{Colors.END}")
        print(f"    - æ‰‹å‹•è¨­ç½®æ‰€æœ‰åƒæ•¸")
        choices.append(str(len(presets) + 1))
        
        print(f"\n{Colors.WHITE}[0] è¿”å›ä¸»é¸å–®{Colors.END}")
        choices.append("0")
        
        choice = self.get_user_choice("é¸æ“‡å¼·åº¦", choices)
        
        if choice == "0":
            return None
        elif choice == str(len(presets) + 1):
            return "custom"
        else:
            preset_idx = int(choice) - 1
            return presets[preset_idx]['key']
    
    def confirm_execution(self, workflow_type: str, preset_name: str, config: Dict) -> bool:
        """ç¢ºèªåŸ·è¡Œé…ç½®"""
        title_map = {
            'training': 'è¨“ç·´AIæ¨¡å‹',
            'evaluation': 'æ•ˆèƒ½é©—è­‰',
            'complete': 'å®Œæ•´å¯¦é©—æµç¨‹'
        }
        
        print(f"\n{Colors.YELLOW}{Colors.BOLD}{'='*50}")
        print(f"              ç¢ºèªåŸ·è¡Œé…ç½®")
        print(f"{'='*50}{Colors.END}")
        
        print(f"\n{Colors.WHITE}å¯¦é©—é¡å‹:{Colors.END} {title_map.get(workflow_type, workflow_type)}")
        print(f"{Colors.WHITE}é…ç½®æ¨¡å¼:{Colors.END} {preset_name}")
        
        # é¡¯ç¤ºé…ç½®æ‘˜è¦
        if 'training' in config:
            training = config['training']
            print(f"\n{Colors.WHITE}ğŸ¤– è¨“ç·´é…ç½®:{Colors.END}")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ–°æ ¼å¼ï¼ˆè«–æ–‡ç´šå¯¦é©—ï¼‰
            if any('_' in task_name for task_name in training.keys()):
                # æ–°æ ¼å¼ï¼šç›´æ¥åˆ—å‡ºä»»å‹™
                dqn_tasks = [name for name in training.keys() if name.startswith('dqn_')]
                nerl_tasks = [name for name in training.keys() if name.startswith('nerl_')]
                
                print(f"  - DQN ä»»å‹™: {len(dqn_tasks)} å€‹ ({', '.join(dqn_tasks)})")
                print(f"  - NERL ä»»å‹™: {len(nerl_tasks)} å€‹ ({', '.join(nerl_tasks)})")
                
                # é¡¯ç¤ºç¸½è©•ä¼°æ­¥æ•¸
                if 'total_eval_steps' in config:
                    steps = config['total_eval_steps']
                    print(f"  - ç¸½è©•ä¼°æ­¥æ•¸: {steps:,} æ­¥ ({steps/1e6:.1f}M)")
            else:
                # èˆŠæ ¼å¼
                print(f"  - DQN: {training.get('dqn_ticks', 'N/A')} ticks")
                print(f"  - NERL: {training.get('nerl_generations', 'N/A')}ä»£, {training.get('nerl_population', 'N/A')}å€‹é«”")
        
        if 'evaluation' in config:
            evaluation = config['evaluation']
            print(f"\n{Colors.WHITE}ğŸ“Š è©•ä¼°é…ç½®:{Colors.END}")
            print(f"  - è©•ä¼°æ™‚é•·: {evaluation.get('ticks', 'N/A')} ticks")
            print(f"  - é‡è¤‡æ¬¡æ•¸: {evaluation.get('repeats', 'N/A')} æ¬¡")
            print(f"  - æ§åˆ¶å™¨æ•¸: 6å€‹ (time_based, queue_based, dqn_step, dqn_global, nerl_step, nerl_global)")
        
        # ä¸¦è¡ŒåŸ·è¡Œè¨­ç½®
        parallel_config = self.config_manager.ask_parallel_execution()
        config['parallel'] = parallel_config
        
        # è³‡æºè² è¼‰é ä¼°ï¼ˆåœ¨ç”¨æˆ¶ç¢ºèªä¸¦è¡Œè¨­ç½®å¾Œé¡¯ç¤ºï¼‰
        if workflow_type == 'training':
            self.config_manager.calculate_and_display_process_load(config)
        
        # NetLogo è¦–è¦ºåŒ–è¨­ç½®
        use_netlogo = self.config_manager.ask_netlogo_mode()
        config['netlogo'] = use_netlogo
        
        # æ—¥èªŒç´šåˆ¥è¨­ç½®
        log_level = self.config_manager.ask_log_level()
        config['log_level'] = log_level
        print(f"{Colors.CYAN}[DEBUG] è¨­ç½®çš„æ—¥èªŒç´šåˆ¥: {log_level}{Colors.END}")
        
        # é ä¼°æ™‚é–“
        estimated_time = self._estimate_execution_time(config)
        print(f"\n{Colors.BOLD}â±ï¸  é ä¼°åŸ·è¡Œæ™‚é–“: {estimated_time}{Colors.END}")
        
        choice = input(f"\n{Colors.CYAN}ç¢ºèªé–‹å§‹åŸ·è¡Œ? [Y/n]: {Colors.END}").strip().lower()
        return choice not in ['n', 'no', 'å¦']
    
    def _estimate_execution_time(self, config: Dict) -> str:
        """é ä¼°åŸ·è¡Œæ™‚é–“"""
        total_minutes = 0
        
        if 'training' in config:
            # è¨“ç·´æ™‚é–“ä¼°ç®—
            dqn_time = config['training'].get('dqn_ticks', 0) / 1000 * 2  # æ¯1000 ticksç´„2åˆ†é˜
            nerl_time = config['training'].get('nerl_generations', 0) * 3  # æ¯ä»£ç´„3åˆ†é˜
            training_time = (dqn_time * 2 + nerl_time * 2)  # 4å€‹æ¨¡å‹
            
            if config.get('parallel', {}).get('enabled', True):
                training_time *= 0.4  # ä¸¦è¡ŒåŸ·è¡Œç¯€çœæ™‚é–“
            
            total_minutes += training_time
        
        if 'evaluation' in config:
            # è©•ä¼°æ™‚é–“ä¼°ç®—
            eval_single = config['evaluation'].get('ticks', 0) / 1000 * 3  # æ¯1000 ticksç´„3åˆ†é˜
            eval_count = config['evaluation'].get('repeats', 1)
            evaluation_time = eval_single * eval_count
            
            if config.get('parallel', {}).get('enabled', True):
                evaluation_time *= 0.5  # ä¸¦è¡ŒåŸ·è¡Œç¯€çœæ™‚é–“
            
            total_minutes += evaluation_time
        
        if 'analysis' in config or config.get('auto_analysis', True):
            total_minutes += 10  # åœ–è¡¨ç”Ÿæˆç´„10åˆ†é˜
        
        if total_minutes < 60:
            return f"ç´„ {total_minutes:.0f} åˆ†é˜"
        else:
            hours = total_minutes / 60
            return f"ç´„ {hours:.1f} å°æ™‚"
    
    def run_training_workflow(self):
        """åŸ·è¡Œè¨“ç·´å·¥ä½œæµç¨‹"""
        preset_name = self.show_preset_menu('training')
        if not preset_name:
            return
        
        if preset_name == "custom":
            # è‡ªå®šç¾©è¨“ç·´é…ç½®
            custom_config = self.config_manager.interactive_training_config()
            preset_display = "è‡ªå®šç¾©é…ç½®"
            
            # å°‡èˆŠæ ¼å¼è½‰æ›ç‚ºæ–°æ ¼å¼
            training_config = {}
            if 'configs' in custom_config:
                # å¾ configs å­—å…¸ä¸­æå–ä»»å‹™
                for task_name, task_config in custom_config['configs'].items():
                    training_config[task_name] = task_config
            else:
                # å¦‚æœæ²’æœ‰ configsï¼Œèªªæ˜æ˜¯ç›´æ¥æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                training_config = custom_config
        else:
            # ä½¿ç”¨é è¨­é…ç½®
            preset = get_preset(preset_name)
            preset_display = preset['name']
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ–°æ ¼å¼ï¼ˆè«–æ–‡ç´šå¯¦é©—ï¼‰
            if any('_' in task_name for task_name in preset['training'].keys()):
                # æ–°æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨é è¨­ä¸­å®šç¾©çš„ä»»å‹™
                training_config = preset['training'].copy()
            else:
                # èˆŠæ ¼å¼ï¼šåŸºæ–¼ reward_modes ç”Ÿæˆé…ç½®
                training_config = {
                    'agents': ['dqn', 'nerl'],
                    'reward_modes': preset['training']['reward_modes'],
                    'configs': {
                        'dqn_step': self.config_manager.get_training_config('dqn', 'step', **preset['training']),
                        'dqn_global': self.config_manager.get_training_config('dqn', 'global', **preset['training']),
                        'nerl_step': self.config_manager.get_training_config('nerl', 'step', **preset['training']),
                        'nerl_global': self.config_manager.get_training_config('nerl', 'global', **preset['training'])
                    }
                }
        
        # æ§‹å»ºå®Œæ•´é…ç½®
        config = {'training': training_config}
        
        # è¤‡è£½å…¶ä»–é è¨­é…ç½®ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯é è¨­é…ç½®ï¼‰
        if preset_name != "custom":
            for key in ['evaluation', 'charts', 'parallel', 'total_eval_steps']:
                if key in preset:
                    config[key] = preset[key]
        
        if self.confirm_execution('training', preset_display, config):
            parallel = config.get('parallel', {}).get('enabled', True)
            print(f"[DEBUG] åˆå§‹ä¸¦è¡Œè¨­ç½®: {parallel}")
            # å°‡ use_new_windows è¨­ç½®å‚³éåˆ°æ¯å€‹è¨“ç·´é…ç½®ä¸­
            use_new_windows = config.get('parallel', {}).get('use_new_windows', True)
            print(f"[DEBUG] æ–°è¦–çª—æ¨¡å¼: {use_new_windows}")
            
            # ç§»é™¤æ–°è¦–çª—æ¨¡å¼ä¸‹çš„ä¸¦è¡ŒåŸ·è¡Œè­¦å‘Š
            # è®“ç”¨æˆ¶è‡ªè¡Œæ±ºå®šæ˜¯å¦ä½¿ç”¨ä¸¦è¡ŒåŸ·è¡Œ
            
            print(f"[DEBUG] æœ€çµ‚ä¸¦è¡Œè¨­ç½®: {parallel}")
            
            # ä¿®æ­£ï¼šç¢ºä¿é ‚å±¤çš„æ—¥èªŒç´šåˆ¥è¢«å‚³éåˆ°æ¯å€‹å­é…ç½®ä¸­
            log_level = config.get('log_level', 'INFO')
            print(f"{Colors.CYAN}[DEBUG] å‚³éçµ¦å­é…ç½®çš„æ—¥èªŒç´šåˆ¥: {log_level}{Colors.END}")
            
            # æª¢æŸ¥é…ç½®æ ¼å¼ä¸¦ç›¸æ‡‰åœ°è¨­ç½®åƒæ•¸
            if 'configs' in training_config:
                # èˆŠæ ¼å¼
                for key in training_config['configs'].keys():
                    training_config['configs'][key]['use_new_windows'] = use_new_windows
                    training_config['configs'][key]['use_netlogo'] = config.get('netlogo', False)
                    training_config['configs'][key]['log_level'] = log_level
                    print(f"{Colors.CYAN}[DEBUG] {key} çš„æ—¥èªŒç´šåˆ¥è¨­ç½®ç‚º: {training_config['configs'][key]['log_level']}{Colors.END}")
            else:
                # æ–°æ ¼å¼ï¼šç›´æ¥è¨­ç½®ä»»å‹™é…ç½®
                for task_name, task_config in training_config.items():
                    if isinstance(task_config, dict):
                        task_config['use_new_windows'] = use_new_windows
                        task_config['use_netlogo'] = config.get('netlogo', False)
                        task_config['log_level'] = log_level
                        print(f"{Colors.CYAN}[DEBUG] {task_name} çš„æ—¥èªŒç´šåˆ¥è¨­ç½®ç‚º: {task_config['log_level']}{Colors.END}")

            # æ§‹å»ºä¸¦è¡Œé…ç½®å­—å…¸
            parallel_config = config.get('parallel', {})
            parallel_config.update({
                'enabled': parallel,
                'use_new_windows': use_new_windows,
                'log_level': log_level
            })
            
            results = self.workflow_runner.run_training_workflow(training_config, parallel_config)
            self._show_workflow_results('training', results)
    
    def run_evaluation_workflow(self):
        """åŸ·è¡Œè©•ä¼°å·¥ä½œæµç¨‹"""
        preset_name = self.show_preset_menu('evaluation')
        if not preset_name:
            return
        
        if preset_name == "custom":
            # è‡ªå®šç¾©è©•ä¼°é…ç½®
            evaluation_config = self.config_manager.interactive_evaluation_config()
            preset_display = "è‡ªå®šç¾©é…ç½®"
        else:
            # ä½¿ç”¨é è¨­é…ç½®
            preset = get_preset(preset_name)
            evaluation_config = self.config_manager.get_evaluation_config(**preset['evaluation'])
            preset_display = preset['name']
        
        config = {'evaluation': evaluation_config}
        
        if self.confirm_execution('evaluation', preset_display, config):
            parallel = config.get('parallel', {}).get('enabled', True)
            # å°‡ use_new_windows è¨­ç½®å‚³éåˆ°è©•ä¼°é…ç½®ä¸­
            use_new_windows = config.get('parallel', {}).get('use_new_windows', True)
            
            # å¦‚æœä½¿ç”¨æ–°è¦–çª—ï¼Œå»ºè­°é—œé–‰ä¸¦è¡ŒåŸ·è¡Œ
            if use_new_windows and parallel:
                print(f"\n{Colors.WARNING}âš ï¸  æ³¨æ„ï¼šæ–°è¦–çª—æ¨¡å¼ä¸‹å»ºè­°é—œé–‰ä¸¦è¡ŒåŸ·è¡Œ{Colors.END}")
                print("å› ç‚ºæ¯å€‹è©•ä¼°éƒ½æœƒç­‰å¾…å®Œæˆï¼Œä¸¦è¡ŒåŸ·è¡Œç„¡æ³•ç™¼æ®æ•ˆæœ")
                choice = input(f"\n{Colors.CYAN}æ˜¯å¦é—œé–‰ä¸¦è¡ŒåŸ·è¡Œï¼Ÿ[Y/n]: {Colors.END}").strip().lower()
                if choice != 'n':
                    parallel = False
                    print(f"{Colors.CYAN}å·²é—œé–‰ä¸¦è¡ŒåŸ·è¡Œ{Colors.END}")
                    
            evaluation_config['use_new_windows'] = use_new_windows
            # å‚³é NetLogo è¨­ç½®
            evaluation_config['use_netlogo'] = config.get('netlogo', False)
            # å‚³éæ—¥èªŒç´šåˆ¥è¨­ç½®
            evaluation_config['log_level'] = config.get('log_level', 'INFO')
            results = self.workflow_runner.run_evaluation_workflow(evaluation_config, parallel)
            self._show_workflow_results('evaluation', results)
    
    def run_analysis_workflow(self):
        """åŸ·è¡Œåˆ†æå·¥ä½œæµç¨‹"""
        print(f"\n{Colors.YELLOW}{Colors.BOLD}{'='*50}")
        print("              æ•¸æ“šåˆ†æèˆ‡åœ–è¡¨")
        print(f"{'='*50}{Colors.END}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è©•ä¼°çµæœ
        results_dir = self.workflow_runner.results_dir / "evaluations"
        eval_dirs = list(results_dir.glob("EVAL_*")) if results_dir.exists() else []
        
        if not eval_dirs:
            print(f"\n{Colors.WARNING}âŒ æ²’æœ‰æ‰¾åˆ°è©•ä¼°çµæœ{Colors.END}")
            print("è«‹å…ˆåŸ·è¡Œ [2] æ•ˆèƒ½é©—è­‰ æˆ– [4] å®Œæ•´å¯¦é©—æµç¨‹")
            input(f"\n{Colors.CYAN}æŒ‰ Enter ç¹¼çºŒ...{Colors.END}")
            return
        
        print(f"\n{Colors.WHITE}æ‰¾åˆ°ä»¥ä¸‹å¯¦é©—çµæœ:{Colors.END}\n")
        
        # é¡¯ç¤ºå¯ç”¨çµæœ
        choices = []
        for i, eval_dir in enumerate(eval_dirs[-5:], 1):  # é¡¯ç¤ºæœ€è¿‘5å€‹çµæœ
            choices.append(str(i))
            mod_time = datetime.fromtimestamp(eval_dir.stat().st_mtime)
            print(f"{Colors.WHITE}[{i}] {eval_dir.name}{Colors.END}")
            print(f"    ç”Ÿæˆæ™‚é–“: {mod_time.strftime('%Y-%m-%d %H:%M')}")
            print()
        
        print(f"{Colors.WHITE}[{len(choices) + 1}] ğŸ“Š ç‚ºæ‰€æœ‰çµæœç”Ÿæˆåœ–è¡¨{Colors.END}")
        choices.append(str(len(choices) + 1))
        
        print(f"{Colors.WHITE}[{len(choices) + 1}] ğŸ”§ è‡ªå®šç¾©åœ–è¡¨è¨­ç½®{Colors.END}")
        choices.append(str(len(choices) + 1))
        
        print(f"\n{Colors.WHITE}[0] è¿”å›ä¸»é¸å–®{Colors.END}")
        choices.append("0")
        
        choice = self.get_user_choice("é¸æ“‡æ“ä½œ", choices)
        
        if choice == "0":
            return
        elif choice == str(len(eval_dirs) + 1):
            # ç‚ºæ‰€æœ‰çµæœç”Ÿæˆåœ–è¡¨
            chart_config = {}
            results = self.workflow_runner.run_analysis_workflow(chart_config)
        elif choice == str(len(eval_dirs) + 2):
            # è‡ªå®šç¾©åœ–è¡¨è¨­ç½®
            chart_config = self.config_manager.interactive_chart_config()
            results = self.workflow_runner.run_analysis_workflow(chart_config)
        else:
            # å–®å€‹çµæœåˆ†æ
            selected_idx = int(choice) - 1
            if 0 <= selected_idx < len(eval_dirs):
                selected_dir = eval_dirs[selected_idx].name
                print(f"\n{Colors.CYAN}åˆ†æé¸å®šçš„å¯¦é©—: {selected_dir}{Colors.END}")
                results = self.workflow_runner.run_analysis_workflow({}, selected_dir)
            else:
                print(f"{Colors.RED}ç„¡æ•ˆçš„é¸æ“‡{Colors.END}")
                return
        
        self._show_workflow_results('analysis', results)
    
    def run_complete_workflow(self):
        """åŸ·è¡Œå®Œæ•´å¯¦é©—æµç¨‹"""
        preset_name = self.show_preset_menu('complete')
        if not preset_name:
            return
        
        if preset_name == "custom":
            print(f"\n{Colors.CYAN}è‡ªå®šç¾©å®Œæ•´å¯¦é©—é…ç½®...{Colors.END}")
            
            # é€æ­¥é…ç½®å„éšæ®µ
            print(f"\n{Colors.WHITE}æ­¥é©Ÿ1: é…ç½®è¨“ç·´åƒæ•¸{Colors.END}")
            training_config = self.config_manager.interactive_training_config()
            
            print(f"\n{Colors.WHITE}æ­¥é©Ÿ2: é…ç½®è©•ä¼°åƒæ•¸{Colors.END}")
            evaluation_config = self.config_manager.interactive_evaluation_config()
            
            print(f"\n{Colors.WHITE}æ­¥é©Ÿ3: é…ç½®åœ–è¡¨åƒæ•¸{Colors.END}")
            chart_config = self.config_manager.interactive_chart_config()
            
            config = {
                'training': training_config,
                'evaluation': evaluation_config,
                'analysis': chart_config,
                'auto_analysis': True
            }
            preset_display = "è‡ªå®šç¾©å®Œæ•´é…ç½®"
        else:
            # ä½¿ç”¨é è¨­é…ç½®
            preset = get_preset(preset_name)
            
            # æ§‹å»ºå®Œæ•´é…ç½®
            training_config = {
                'agents': ['dqn', 'nerl'],
                'reward_modes': preset['training']['reward_modes'],
                'configs': {
                    'dqn_step': self.config_manager.get_training_config('dqn', 'step', **preset['training']),
                    'dqn_global': self.config_manager.get_training_config('dqn', 'global', **preset['training']),
                    'nerl_step': self.config_manager.get_training_config('nerl', 'step', **preset['training']),
                    'nerl_global': self.config_manager.get_training_config('nerl', 'global', **preset['training'])
                }
            }
            
            evaluation_config = self.config_manager.get_evaluation_config(**preset['evaluation'])
            chart_config = self.config_manager.get_chart_config(**preset.get('charts', {}))
            
            config = {
                'training': training_config,
                'evaluation': evaluation_config,
                'analysis': chart_config,
                'auto_analysis': True
            }
            preset_display = preset['name']
        
        if self.confirm_execution('complete', preset_display, config):
            parallel = config.get('parallel', {}).get('enabled', True)
            results = self.workflow_runner.run_complete_workflow(config, parallel)
            self._show_complete_results(results)
    
    def run_custom_config(self):
        """åŸ·è¡Œè‡ªå®šç¾©åƒæ•¸è¨­ç½®"""
        print(f"\n{Colors.YELLOW}{Colors.BOLD}{'='*50}")
        print("              è‡ªå®šç¾©åƒæ•¸è¨­ç½®")
        print(f"{'='*50}{Colors.END}")
        
        print(f"\n{Colors.WHITE}[1] ğŸ¤– è‡ªå®šç¾©è¨“ç·´åƒæ•¸{Colors.END}")
        print(f"    - DQNè¨“ç·´æ™‚é•·ã€NERLä»£æ•¸ã€æ—ç¾¤å¤§å°ç­‰")
        
        print(f"\n{Colors.WHITE}[2] ğŸ“Š è‡ªå®šç¾©è©•ä¼°åƒæ•¸{Colors.END}")
        print(f"    - è©•ä¼°æ™‚é•·ã€é‡è¤‡æ¬¡æ•¸ã€éš¨æ©Ÿç¨®å­ç­‰")
        
        print(f"\n{Colors.WHITE}[3] ğŸ“ˆ è‡ªå®šç¾©åœ–è¡¨åƒæ•¸{Colors.END}")
        print(f"    - åœ–è¡¨é¡å‹ã€è§£æåº¦ã€æ ¼å¼ç­‰")
        
        print(f"\n{Colors.WHITE}[4] âš¡ ä¸¦è¡ŒåŸ·è¡Œè¨­ç½®{Colors.END}")
        print(f"    - æ˜¯å¦å•Ÿç”¨å¤šç·šç¨‹ã€æœ€å¤§ä¸¦è¡Œæ•¸ç­‰")
        
        print(f"\n{Colors.WHITE}[5] ğŸ’¾ è¼‰å…¥/ä¿å­˜é…ç½®{Colors.END}")
        print(f"    - ä¿å­˜ç•¶å‰è¨­ç½®æˆ–è¼‰å…¥å·²ä¿å­˜çš„é…ç½®")
        
        print(f"\n{Colors.WHITE}[0] è¿”å›ä¸»é¸å–®{Colors.END}")
        
        choice = self.get_user_choice("é¸æ“‡æ“ä½œ", ["1", "2", "3", "4", "5", "0"])
        
        if choice == "0":
            return
        elif choice == "1":
            self.config_manager.interactive_training_config()
        elif choice == "2":
            self.config_manager.interactive_evaluation_config()
        elif choice == "3":
            self.config_manager.interactive_chart_config()
        elif choice == "4":
            self.config_manager.ask_parallel_execution()
        elif choice == "5":
            self.config_manager.interactive_config_management()
        
        input(f"\n{Colors.CYAN}æŒ‰ Enter ç¹¼çºŒ...{Colors.END}")
    
    def _show_workflow_results(self, workflow_type: str, results: Dict):
        """é¡¯ç¤ºå·¥ä½œæµç¨‹çµæœ"""
        title_map = {
            'training': 'è¨“ç·´çµæœ',
            'evaluation': 'è©•ä¼°çµæœ',
            'analysis': 'åˆ†æçµæœ'
        }
        
        print(f"\n{Colors.GREEN}{Colors.BOLD}{'='*50}")
        print(f"              {title_map.get(workflow_type, 'åŸ·è¡Œçµæœ')}")
        print(f"{'='*50}{Colors.END}")
        
        if not results:
            print(f"\n{Colors.WARNING}âŒ æ²’æœ‰åŸ·è¡Œçµæœ{Colors.END}")
            input(f"\n{Colors.CYAN}æŒ‰ Enter ç¹¼çºŒ...{Colors.END}")
            return
        
        successful = sum(1 for success in results.values() if success)
        total = len(results)
        success_rate = (successful / total) * 100 if total > 0 else 0
        
        color = Colors.GREEN if success_rate >= 80 else Colors.YELLOW if success_rate >= 50 else Colors.RED
        
        print(f"\n{Colors.WHITE}åŸ·è¡Œçµ±è¨ˆ:{Colors.END}")
        print(f"  {color}æˆåŠŸ: {successful}/{total} ({success_rate:.1f}%){Colors.END}")
        
        print(f"\n{Colors.WHITE}è©³ç´°çµæœ:{Colors.END}")
        for task_name, success in results.items():
            status_icon = "âœ…" if success else "âŒ"
            status_color = Colors.GREEN if success else Colors.RED
            print(f"  {status_color}{status_icon} {task_name}{Colors.END}")
        
        input(f"\n{Colors.CYAN}æŒ‰ Enter ç¹¼çºŒ...{Colors.END}")
    
    def _show_complete_results(self, results: Dict):
        """é¡¯ç¤ºå®Œæ•´å¯¦é©—çµæœ"""
        print(f"\n{Colors.GREEN}{Colors.BOLD}{'='*60}")
        print("                  å®Œæ•´å¯¦é©—çµæœ")
        print(f"{'='*60}{Colors.END}")
        
        stage_names = {
            'training': 'ğŸ¤– æ¨¡å‹è¨“ç·´',
            'evaluation': 'ğŸ“Š æ•ˆèƒ½è©•ä¼°',
            'analysis': 'ğŸ“ˆ æ•¸æ“šåˆ†æ'
        }
        
        overall_stats = {'total': 0, 'successful': 0}
        
        for stage, stage_results in results.items():
            if stage_results:
                successful = sum(1 for success in stage_results.values() if success)
                total = len(stage_results)
                success_rate = (successful / total) * 100 if total > 0 else 0
                
                overall_stats['total'] += total
                overall_stats['successful'] += successful
                
                color = Colors.GREEN if success_rate >= 80 else Colors.YELLOW if success_rate >= 50 else Colors.RED
                stage_name = stage_names.get(stage, stage)
                
                print(f"\n{Colors.WHITE}{stage_name}:{Colors.END}")
                print(f"  {color}æˆåŠŸç‡: {successful}/{total} ({success_rate:.1f}%){Colors.END}")
        
        # æ•´é«”æˆåŠŸç‡
        if overall_stats['total'] > 0:
            overall_rate = (overall_stats['successful'] / overall_stats['total']) * 100
            overall_color = Colors.GREEN if overall_rate >= 80 else Colors.YELLOW if overall_rate >= 50 else Colors.RED
            
            print(f"\n{Colors.BOLD}ğŸ“Š æ•´é«”æˆåŠŸç‡: {overall_color}{overall_stats['successful']}/{overall_stats['total']} ({overall_rate:.1f}%){Colors.END}")
        
        # é¡¯ç¤ºçµæœä½ç½®
        print(f"\n{Colors.WHITE}çµæœæ–‡ä»¶ä½ç½®:{Colors.END}")
        if 'evaluation' in results:
            eval_dirs = list(self.workflow_runner.results_dir.glob("evaluations/EVAL_*"))
            if eval_dirs:
                latest_eval = max(eval_dirs, key=lambda x: x.stat().st_mtime)
                print(f"  ğŸ“Š æœ€æ–°è©•ä¼°çµæœ: {latest_eval}")
        
        if 'analysis' in results:
            print(f"  ğŸ“ˆ åœ–è¡¨æ–‡ä»¶: result/evaluations/*/charts/")
        
        # åŸ·è¡Œçµ±è¨ˆ
        stats = self.workflow_runner.get_execution_stats()
        if stats.get('start_time') and stats.get('end_time'):
            total_time = (stats['end_time'] - stats['start_time']).total_seconds() / 60
            print(f"  â±ï¸  ç¸½è€—æ™‚: {total_time:.1f} åˆ†é˜")
        
        print(f"\n{Colors.CYAN}ğŸ‰ å®Œæ•´å¯¦é©—æµç¨‹åŸ·è¡Œå®Œæˆï¼{Colors.END}")
        input(f"\n{Colors.CYAN}æŒ‰ Enter ç¹¼çºŒ...{Colors.END}")
    
    def run(self):
        """é‹è¡Œä¸»ç¨‹åº"""
        try:
            self.show_banner()
            
            while True:
                self.show_main_menu()
                choice = self.get_user_choice()
                
                if choice == "1":
                    self.run_training_workflow()
                
                elif choice == "2":
                    self.run_evaluation_workflow()
                
                elif choice == "3":
                    self.run_analysis_workflow()
                
                elif choice == "4":
                    self.run_complete_workflow()
                
                elif choice == "5":
                    self.run_custom_config()
                
                elif choice == "0":
                    print(f"\n{Colors.CYAN}æ„Ÿè¬ä½¿ç”¨ RMFS å¯¦é©—ç®¡ç†ç³»çµ±ï¼{Colors.END}")
                    print(f"{Colors.YELLOW}å¦‚æœ‰å•é¡Œè«‹æŸ¥çœ‹æ–‡æª”æˆ–è¯ç¹«é–‹ç™¼è€…ã€‚{Colors.END}\n")
                    break
        
        except KeyboardInterrupt:
            print(f"\n\n{Colors.YELLOW}ç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·{Colors.END}")
        except Exception as e:
            print(f"\n{Colors.RED}ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}{Colors.END}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»å‡½æ•¸"""
    # æª¢æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 6):
        print("âŒ éœ€è¦ Python 3.6 æˆ–æ›´é«˜ç‰ˆæœ¬")
        sys.exit(1)
    
    # æª¢æŸ¥æ˜¯å¦åœ¨æ­£ç¢ºçš„ç›®éŒ„
    expected_files = ['train.py', 'evaluate.py', 'visualization_generator.py']
    missing_files = [f for f in expected_files if not Path(f).exists()]
    
    if missing_files:
        print(f"âŒ æ‰¾ä¸åˆ°å¿…è¦çš„æ–‡ä»¶: {', '.join(missing_files)}")
        print("è«‹ç¢ºä¿åœ¨æ­£ç¢ºçš„å°ˆæ¡ˆç›®éŒ„ä¸­é‹è¡Œæ­¤è…³æœ¬")
        sys.exit(1)
    
    # å•Ÿå‹•ç®¡ç†å™¨
    manager = SimpleExperimentManager()
    manager.run()

if __name__ == "__main__":
    main()