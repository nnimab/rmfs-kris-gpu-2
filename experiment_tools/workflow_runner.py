"""
å·¥ä½œæµç¨‹åŸ·è¡Œå™¨
==============

å¯¦ç¾è¨“ç·´ã€è©•ä¼°ã€åˆ†æçš„å…·é«”åŸ·è¡Œé‚è¼¯ï¼Œæ”¯æ´ä¸¦è¡Œè™•ç†
"""

import os
import sys
import time
import subprocess
import glob
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Tuple, Optional, Any

class Colors:
    """æ§åˆ¶å°é¡è‰²"""
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    WARNING = '\033[93m'  # æ–°å¢ WARNING å±¬æ€§
    END = '\033[0m'

class WorkflowRunner:
    """å¯¦é©—å·¥ä½œæµç¨‹åŸ·è¡Œå™¨"""
    
    def __init__(self, project_root: str = None):
        """
        åˆå§‹åŒ–å·¥ä½œæµç¨‹åŸ·è¡Œå™¨
        
        Args:
            project_root: å°ˆæ¡ˆæ ¹ç›®éŒ„è·¯å¾‘
        """
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.models_dir = self.project_root / "models"
        self.results_dir = self.project_root / "result"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.models_dir.mkdir(exist_ok=True)
        self.results_dir.mkdir(exist_ok=True)
        
        # åŸ·è¡Œçµ±è¨ˆ
        self.execution_stats = {
            "start_time": None,
            "end_time": None,
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "results": {}
        }
        
        # ä¸¦è¡Œé…ç½®
        self.parallel_config = {}
        
        # è¨“ç·´è…³æœ¬è·¯å¾‘å’Œ Python å¯åŸ·è¡Œæª”
        self.train_script_path = self.project_root / "train.py"
        self.python_executable = sys.executable
        # èª¿è©¦ï¼šé¡¯ç¤º Python åŸ·è¡Œæª”è·¯å¾‘
        print(f"DEBUG: Python executable path: '{self.python_executable}'")
        self.log_level = "INFO"  # é è¨­æ—¥èªŒç´šåˆ¥
    
    def print_header(self, text: str, color: str = Colors.BLUE):
        """æ‰“å°æ¨™é¡Œ"""
        print(f"\n{color}{Colors.BOLD}{'='*60}")
        print(f"  {text}")
        print(f"{'='*60}{Colors.END}")
    
    def print_success(self, text: str):
        """æ‰“å°æˆåŠŸè¨Šæ¯"""
        print(f"{Colors.GREEN}[SUCCESS] {text}{Colors.END}")
    
    def print_error(self, text: str):
        """æ‰“å°éŒ¯èª¤è¨Šæ¯"""
        print(f"{Colors.RED}[ERROR] {text}{Colors.END}")
    
    def print_warning(self, text: str):
        """æ‰“å°è­¦å‘Šè¨Šæ¯"""
        print(f"{Colors.YELLOW}[WARNING] {text}{Colors.END}")
    
    def print_info(self, text: str):
        """æ‰“å°ä¿¡æ¯"""
        print(f"{Colors.CYAN}[INFO] {text}{Colors.END}")
    
    def print_progress(self, current: int, total: int, description: str):
        """æ‰“å°é€²åº¦æ¢"""
        if total == 0:
            return
        
        percentage = (current / total) * 100
        bar_length = 30
        filled_length = int(bar_length * current // total)
        bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
        
        print(f"\r{Colors.BLUE}[{bar}] {percentage:.1f}% - {description}{Colors.END}", end='', flush=True)
        if current == total:
            print()  # æ›è¡Œ
    
    def run_command(self, cmd: str, description: str, timeout: int = 600, 
                   open_new_window: bool = False, window_title: str = None) -> Tuple[bool, str]:
        """
        åŸ·è¡Œå‘½ä»¤
        
        Args:
            cmd: è¦åŸ·è¡Œçš„å‘½ä»¤
            description: æè¿°
            timeout: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
            open_new_window: æ˜¯å¦åœ¨æ–°è¦–çª—ä¸­åŸ·è¡Œ
            window_title: æ–°è¦–çª—æ¨™é¡Œ
            
        Returns:
            tuple: (æ˜¯å¦æˆåŠŸ, è¼¸å‡º/éŒ¯èª¤è¨Šæ¯)
        """
        self.print_info(f"åŸ·è¡Œ: {description}")
        print(f"å‘½ä»¤: {cmd}")
        
        if open_new_window:
            # åœ¨æ–°çš„çµ‚ç«¯è¦–çª—ä¸­åŸ·è¡Œå‘½ä»¤
            if not window_title:
                window_title = description
            
            # Windows CMD æ–°è¦–çª—å‘½ä»¤
            # ä½¿ç”¨ /K ä¿æŒè¦–çª—é–‹å•Ÿï¼Œé¡¯ç¤ºçµæœ
            # å‰µå»ºä¸€å€‹è‡¨æ™‚æª”æ¡ˆä¾†æ¨™è¨˜å®Œæˆç‹€æ…‹
            import tempfile
            temp_dir = tempfile.gettempdir()
            done_flag = os.path.join(temp_dir, f"rmfs_done_{window_title.replace(' ', '_')}.flag")
            
            # åˆªé™¤èˆŠçš„æ¨™è¨˜æª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if os.path.exists(done_flag):
                os.remove(done_flag)
            
            # ä¿®æ”¹å‘½ä»¤ï¼Œç„¡è«–æˆåŠŸæˆ–å¤±æ•—éƒ½å‰µå»ºæ¨™è¨˜æª”æ¡ˆï¼ˆåŒ…å«çµæœï¼‰
            window_cmd = f'''start "{window_title}" cmd /K "cd /d {self.project_root} && ({cmd} && echo SUCCESS > "{done_flag}" || echo FAILED > "{done_flag}") && echo. && echo åŸ·è¡Œå®Œæˆï¼ŒæŒ‰ä»»æ„éµé—œé–‰è¦–çª—... && pause"'''
            
            try:
                # å•Ÿå‹•æ–°è¦–çª—
                process = subprocess.Popen(window_cmd, shell=True, cwd=str(self.project_root))
                self.print_success(f"å·²åœ¨æ–°è¦–çª—å•Ÿå‹•: {window_title}")
                
                # ç­‰å¾…è¨“ç·´å®Œæˆï¼ˆæª¢æŸ¥æ¨™è¨˜æª”æ¡ˆï¼‰
                self.print_info(f"ç­‰å¾… {window_title} å®Œæˆ...")
                start_time = time.time()
                check_interval = 5  # æ¯5ç§’æª¢æŸ¥ä¸€æ¬¡
                
                while True:
                    if os.path.exists(done_flag):
                        # è¨“ç·´å®Œæˆï¼Œè®€å–çµæœ
                        with open(done_flag, 'r') as f:
                            result = f.read().strip()
                        os.remove(done_flag)  # æ¸…ç†æ¨™è¨˜æª”æ¡ˆ
                        elapsed = time.time() - start_time
                        print()  # æ›è¡Œï¼Œæ¸…é™¤é€²åº¦é¡¯ç¤º
                        
                        if result == "SUCCESS":
                            self.print_success(f"{window_title} å·²æˆåŠŸå®Œæˆ (è€—æ™‚: {elapsed:.1f}ç§’)")
                            return True, f"Process completed successfully in window: {window_title}"
                        else:
                            self.print_error(f"{window_title} åŸ·è¡Œå¤±æ•— (è€—æ™‚: {elapsed:.1f}ç§’)")
                            return False, f"Process failed in window: {window_title}"
                    
                    # æª¢æŸ¥æ˜¯å¦è¶…æ™‚
                    if time.time() - start_time > timeout:
                        self.print_error(f"{window_title} åŸ·è¡Œè¶…æ™‚")
                        return False, "Timeout"
                    
                    # é¡¯ç¤ºç­‰å¾…é€²åº¦
                    elapsed = int(time.time() - start_time)
                    print(f"\rç­‰å¾…ä¸­... {elapsed}ç§’ / {timeout}ç§’", end='', flush=True)
                    time.sleep(check_interval)
                    
                return True, f"Process started in new window: {window_title}"
            except Exception as e:
                self.print_error(f"ç„¡æ³•é–‹å•Ÿæ–°è¦–çª—: {str(e)}")
                return False, str(e)
        else:
            # åŸæœ¬çš„åŸ·è¡Œæ–¹å¼ï¼ˆæ•ç²è¼¸å‡ºï¼‰
            try:
                start_time = time.time()
                result = subprocess.run(
                    cmd, shell=True, capture_output=True, 
                    text=True, timeout=timeout, cwd=str(self.project_root)
                )
                elapsed_time = time.time() - start_time
                
                if result.returncode == 0:
                    self.print_success(f"å®Œæˆ (è€—æ™‚: {elapsed_time:.1f}ç§’)")
                    return True, result.stdout
                else:
                    self.print_error(f"å¤±æ•— (è¿”å›ç¢¼: {result.returncode})")
                    if result.stderr:
                        print(f"éŒ¯èª¤: {result.stderr}")
                    return False, result.stderr
                    
            except subprocess.TimeoutExpired:
                self.print_error(f"è¶…æ™‚ (è¶…é {timeout} ç§’)")
                return False, "Timeout"
            except Exception as e:
                self.print_error(f"ç•°å¸¸: {str(e)}")
                return False, str(e)
    
    def run_training_workflow(self, training_config: Dict, parallel_config: Dict) -> Dict[str, bool]:
        """
        åŸ·è¡Œå¸¶æœ‰é›™å±¤ä¸¦è¡Œæ§åˆ¶çš„è¨“ç·´å·¥ä½œæµç¨‹ã€‚
        å¤–å±¤ä¸¦è¡Œï¼šæ§åˆ¶åŒæ™‚åŸ·è¡Œå¤šå°‘å€‹ç¨ç«‹çš„è¨“ç·´ä»»å‹™
        å…§å±¤ä¸¦è¡Œï¼šæ§åˆ¶æ¯å€‹NERLä»»å‹™å…§éƒ¨ä½¿ç”¨å¤šå°‘å€‹è©•ä¼°é€²ç¨‹
        """
        self.print_header("é–‹å§‹AIæ¨¡å‹è¨“ç·´å·¥ä½œæµç¨‹ï¼ˆé›™å±¤ä¸¦è¡Œèª¿åº¦å™¨ï¼‰", Colors.MAGENTA)
        self.log_level = parallel_config.get('log_level', 'INFO')

        # 1. æº–å‚™æ‰€æœ‰ä»»å‹™åˆ—è¡¨
        all_tasks = list(training_config.items())
        
        # 2. ç²å–å¤–å±¤ä¸¦è¡Œæ•¸é‡
        max_concurrent_tasks = parallel_config.get('max_workers', 2)
        if not parallel_config.get('enabled', True):
            max_concurrent_tasks = 1  # å¦‚æœæœªå•Ÿç”¨ä¸¦è¡Œï¼Œå‰‡å¼·åˆ¶ç‚º1

        self.print_info(f"èª¿åº¦å™¨è¨­å®šï¼šå°‡ä»¥æœ€å¤š {max_concurrent_tasks} å€‹ä»»å‹™ä¸¦è¡Œçš„æ–¹å¼åŸ·è¡Œã€‚")
        self.print_info(f"ç¸½ä»»å‹™æ•¸: {len(all_tasks)} å€‹ ({len([n for n, _ in all_tasks if 'nerl' in n])} NERL + {len([n for n, _ in all_tasks if 'dqn' in n])} DQN)")
        
        # 3. çœŸæ­£çš„åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥æ§åˆ¶ä¸¦è¡Œæ•¸é‡
        results = {}
        
        # åˆ†æ‰¹è™•ç†
        for i in range(0, len(all_tasks), max_concurrent_tasks):
            current_batch = all_tasks[i:i+max_concurrent_tasks]
            
            self.print_info(f"å•Ÿå‹•ç¬¬ {i//max_concurrent_tasks + 1} æ‰¹ä»»å‹™ï¼ˆ{len(current_batch)} å€‹ï¼‰...")
            
            # å•Ÿå‹•ç•¶å‰æ‰¹æ¬¡çš„æ‰€æœ‰ä»»å‹™
            batch_processes = []
            for name, params in current_batch:
                try:
                    process = self._build_and_run_command(name, params, parallel_config, return_process=True)
                    if process:
                        batch_processes.append((name, process))
                        results[name] = True
                        self.print_success(f"âœ… å·²å•Ÿå‹•ä»»å‹™: {name}")
                    else:
                        results[name] = False
                        self.print_error(f"âŒ ä»»å‹™å•Ÿå‹•å¤±æ•—: {name}")
                except Exception as exc:
                    self.print_error(f"ä»»å‹™ '{name}' åœ¨åŸ·è¡Œèª¿åº¦ä¸­ç”¢ç”Ÿä¾‹å¤–: {exc}")
                    results[name] = False
            
            # å¦‚æœé‚„æœ‰å‰©é¤˜ä»»å‹™ï¼Œç­‰å¾…ç•¶å‰æ‰¹æ¬¡å®Œå…¨å®Œæˆ
            if i + max_concurrent_tasks < len(all_tasks):
                remaining_tasks = len(all_tasks) - i - max_concurrent_tasks
                
                self.print_info(f"å·²å•Ÿå‹• {len(current_batch)} å€‹ä»»å‹™ï¼Œç­‰å¾…å®ƒå€‘å®Œæˆè¨“ç·´...")
                self.print_info(f"å‰©é¤˜ {remaining_tasks} å€‹ä»»å‹™å°‡åœ¨ç•¶å‰æ‰¹æ¬¡å®Œæˆå¾Œå•Ÿå‹•")
                
                # ç­‰å¾…ç•¶å‰æ‰¹æ¬¡çš„æ‰€æœ‰é€²ç¨‹å®Œæˆ
                self._wait_for_batch_completion(batch_processes)
                
                self.print_info("ç•¶å‰æ‰¹æ¬¡è¨“ç·´å·²å®Œæˆï¼Œæº–å‚™å•Ÿå‹•ä¸‹ä¸€æ‰¹...")
                    
        successful_count = sum(1 for v in results.values() if v)
        self.print_header(f"æ‰€æœ‰è¨“ç·´ä»»å‹™å·²åŸ·è¡Œå®Œç•¢ ({successful_count}/{len(all_tasks)} æˆåŠŸå•Ÿå‹•)", Colors.GREEN)
        
        if successful_count > 0:
            self.print_info("âœ¨ æˆåŠŸå•Ÿå‹•çš„è¨“ç·´è¦–çª—å°‡æŒçºŒé‹è¡Œï¼Œæ‚¨å¯ä»¥åœ¨å„å€‹è¦–çª—ä¸­ç›£æ§è¨“ç·´é€²åº¦")
        
        return results
    
    def _run_task_group(self, task_dict: Dict[str, Dict], use_new_windows: bool = True, task_type: str = "") -> Dict[str, bool]:
        """
        åŸ·è¡Œä¸€çµ„è¨“ç·´ä»»å‹™
        
        Args:
            task_dict: ä»»å‹™å­—å…¸ {task_name: task_params}
            use_new_windows: æ˜¯å¦ä½¿ç”¨æ–°è¦–çª—
            task_type: ä»»å‹™é¡å‹æè¿°
            
        Returns:
            dict: åŸ·è¡Œçµæœ {task_name: success}
        """
        results = {}
        task_list = list(task_dict.items())
        
        self.print_info(f"é–‹å§‹åŸ·è¡Œ {len(task_list)} å€‹ {task_type.upper()} ä»»å‹™...")
        
        for task_name, task_params in task_list:
            try:
                self.print_info(f"é–‹å§‹åŸ·è¡Œä»»å‹™: {task_name}")
                
                # è¨­ç½®è¦–çª—æ¨¡å¼
                task_params_copy = task_params.copy()
                task_params_copy['use_new_windows'] = use_new_windows
                task_params_copy['log_level'] = self.log_level
                
                success = self._build_and_run_command(task_name, task_params_copy)
                results[task_name] = success
                
                if success:
                    self.print_success(f"ä»»å‹™ {task_name} å®Œæˆ")
                else:
                    self.print_error(f"ä»»å‹™ {task_name} å¤±æ•—")
                    
            except Exception as e:
                self.print_error(f"ä»»å‹™ {task_name} åŸ·è¡Œç•°å¸¸: {e}")
                results[task_name] = False
        
        return results
    
    def _wait_for_batch_completion(self, batch_processes):
        """ç­‰å¾…ç•¶å‰æ‰¹æ¬¡çš„æ‰€æœ‰ä»»å‹™å®Œæˆ"""
        if not batch_processes:
            return
        
        import time
        import os
        import tempfile
        
        self.print_info(f"æ­£åœ¨ç›£æ§ {len(batch_processes)} å€‹è¨“ç·´ä»»å‹™çš„å®Œæˆç‹€æ…‹...")
        
        # ä½¿ç”¨ä»»å‹™åç¨±è€Œä¸æ˜¯é€²ç¨‹å°è±¡
        task_names = [task_name for task_name, _ in batch_processes]
        completed_tasks = set()
        
        # å‰µå»ºå®Œæˆæ¨™è¨˜æ–‡ä»¶çš„ç›®éŒ„
        temp_dir = tempfile.gettempdir()
        completion_dir = os.path.join(temp_dir, "rmfs_completion_flags")
        os.makedirs(completion_dir, exist_ok=True)
        
        # æ¸…ç†èˆŠçš„å®Œæˆæ¨™è¨˜æ–‡ä»¶
        for task_name in task_names:
            completion_file = os.path.join(completion_dir, f"{task_name}.completed")
            if os.path.exists(completion_file):
                os.remove(completion_file)
        
        # æ¯ 10 ç§’æª¢æŸ¥ä¸€æ¬¡
        while len(completed_tasks) < len(task_names):
            # æª¢æŸ¥å®Œæˆæ¨™è¨˜æ–‡ä»¶
            for task_name in task_names:
                if task_name not in completed_tasks:
                    completion_file = os.path.join(completion_dir, f"{task_name}.completed")
                    if os.path.exists(completion_file):
                        completed_tasks.add(task_name)
                        self.print_success(f"âœ… ä»»å‹™ '{task_name}' è¨“ç·´å®Œæˆ")
                        # æ¸…ç†å®Œæˆæ¨™è¨˜æ–‡ä»¶
                        try:
                            os.remove(completion_file)
                        except:
                            pass
            
            # é¡¯ç¤ºé€²åº¦
            completed_count = len(completed_tasks)
            total_count = len(task_names)
            if completed_count < total_count:
                remaining = total_count - completed_count
                running_tasks = [name for name in task_names if name not in completed_tasks]
                print(f"\rç­‰å¾…ä¸­... {completed_count}/{total_count} å€‹ä»»å‹™å·²å®Œæˆï¼Œé‚„æœ‰ {remaining} å€‹æ­£åœ¨è¨“ç·´: {running_tasks}", end='', flush=True)
                time.sleep(10)  # æ¯ 10 ç§’æª¢æŸ¥ä¸€æ¬¡
        
        print()  # æ›è¡Œ
        self.print_success(f"ç•¶å‰æ‰¹æ¬¡çš„ {len(task_names)} å€‹ä»»å‹™å…¨éƒ¨å®Œæˆï¼")
    
    def _build_and_run_command(self, task_name: str, params: Dict, parallel_config: Dict, return_process=False):
        """æ ¹æ“šä»»å‹™åç¨±å’Œåƒæ•¸ï¼Œæ§‹å»ºä¸¦åœ¨æ–°è¦–çª—ä¸­åŸ·è¡Œè¨“ç·´å‘½ä»¤ã€‚"""
        
        # 1. è§£æ agent å’Œ reward_mode
        parts = task_name.split('_')
        agent = parts[0]
        reward_mode = parts[1]
        
        # è™•ç†è®Šé«”å¾Œç¶´ï¼ˆå¦‚ nerl_step_a -> agent=nerl, reward_mode=step, variant=aï¼‰
        variant = None
        if len(parts) > 2:
            variant = parts[2]

        # 2. æ§‹å»ºåŸºç¤æŒ‡ä»¤
        cmd_list = [
            self.python_executable, 
            str(self.train_script_path),
            '--agent', agent,
            '--reward_mode', reward_mode,
            '--log_level', self.log_level
        ]
        
        # å¦‚æœæœ‰è®Šé«”ï¼Œæ·»åŠ è®Šé«”åƒæ•¸
        if variant:
            cmd_list.extend(['--variant', variant])

        # 3. å¾ params å­—å…¸å‹•æ…‹æ·»åŠ æ‰€æœ‰åƒæ•¸
        # å®šç¾© train.py æ”¯æ´çš„åƒæ•¸åˆ—è¡¨ï¼ˆåŸºæ–¼ train.py çš„ argparse å®šç¾©ï¼‰
        valid_params = {
            'generations', 'population', 'eval_ticks', 'training_ticks', 
            'parallel_workers', 'netlogo', 'ticks'
        }
        
        for key, value in params.items():
            # åªè™•ç† train.py æ”¯æ´çš„åƒæ•¸ï¼Œå¿½ç•¥å…¶ä»–å…ƒæ•¸æ“š
            if key in valid_params:
                # è·³é parallel_workers åƒæ•¸ï¼Œæˆ‘å€‘å°‡æ ¹æ“šé›™å±¤ä¸¦è¡Œé‚è¼¯è™•ç†
                if key == 'parallel_workers':
                    continue
                # ç‰¹æ®Šè™•ç† netlogo åƒæ•¸
                elif key == 'netlogo' and value:
                    cmd_list.append('--netlogo')
                # ç‰¹æ®Šè™•ç† DQN çš„ ticks åƒæ•¸ï¼Œè½‰æ›ç‚º training_ticks
                elif key == 'ticks' and agent == 'dqn':
                    cmd_list.append('--training_ticks')
                    cmd_list.append(str(value))
                elif key != 'netlogo':  # å…¶ä»–é boolean åƒæ•¸
                    cmd_list.append(f"--{key}")
                    cmd_list.append(str(value))

        # --- ã€æ ¸å¿ƒä¿®æ”¹é»ï¼šæ­£ç¢ºè¨­å®š NERL çš„å…§å±¤ä¸¦è¡Œåƒæ•¸ã€‘ ---
        if agent == 'nerl':
            # èª¿è©¦ä¿¡æ¯ï¼šæª¢æŸ¥ parallel_config å…§å®¹
            self.print_info(f"[DEBUG] parallel_config å…§å®¹: {parallel_config}")
            # å¾å…¨åŸŸä¸¦è¡Œé…ç½®ä¸­ç²å– NERL æ‡‰ä½¿ç”¨çš„å…§éƒ¨æ ¸å¿ƒæ•¸
            internal_workers = parallel_config.get('nerl_internal_workers', 4)
            cmd_list.extend(['--parallel_workers', str(internal_workers)])
            self.print_info(f"NERLä»»å‹™ '{task_name}' å°‡ä½¿ç”¨ {internal_workers} å€‹å…§éƒ¨ä¸¦è¡Œé€²ç¨‹")
        # --- ã€ä¿®æ”¹çµæŸã€‘ ---

        # 4. åœ¨æ–°è¦–çª—ä¸­åŸ·è¡Œ
        try:
            # ç¢ºä¿æ‰€æœ‰å‘½ä»¤åƒæ•¸éƒ½æ˜¯å­—ä¸²
            cmd_list_str = [str(item) for item in cmd_list]
            self.print_info(f"ç‚ºä»»å‹™ '{task_name}' æº–å‚™æŒ‡ä»¤: {' '.join(cmd_list_str)}")

            # æ ¹æ“šä½œæ¥­ç³»çµ±ä½¿ç”¨ä¸åŒçš„æŒ‡ä»¤ä¾†é–‹å•Ÿæ–°è¦–çª—
            if os.name == 'nt': # Windows
                # /c æœƒåŸ·è¡Œå®Œå‘½ä»¤å¾Œé—œé–‰è¦–çª—ï¼Œ/k æœƒä¿ç•™è¦–çª—
                # ä½¿ç”¨ /k ä¿ç•™è¦–çª—ï¼Œé€™æ¨£å¯ä»¥çœ‹åˆ°éŒ¯èª¤ä¿¡æ¯å’Œè¨“ç·´çµæœ
                process = subprocess.Popen(['start', f'Training - {task_name}', 'cmd', '/k'] + cmd_list_str, shell=True, cwd=self.project_root)
            else: # macOS & Linux
                # é€™è£¡éœ€è¦æ ¹æ“šæ‚¨çš„é Windows ç’°å¢ƒé€²è¡Œèª¿æ•´ï¼Œä¾‹å¦‚ä½¿ç”¨ 'gnome-terminal' æˆ– 'xterm'
                process = subprocess.Popen(['gnome-terminal', '--', 'bash', '-c', f"{' '.join(cmd_list_str)}; exec bash"], cwd=self.project_root)
            
            # Popen æ˜¯éé˜»å¡çš„ï¼ŒæŒ‡ä»¤ç™¼å‡ºå¾Œç«‹å³è¿”å›
            self.print_success(f"å·²åœ¨æ–°è¦–çª—ä¸­æˆåŠŸå•Ÿå‹•ä»»å‹™: {task_name}")
            
            if return_process:
                return process
            else:
                return True

        except Exception as e:
            self.print_error(f"å•Ÿå‹•ä»»å‹™ '{task_name}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            if return_process:
                return None
            else:
                return False
    
    def _run_training_batch_execution(self, training_tasks: List[Tuple]) -> Dict[str, bool]:
        """
        åˆ†æ‰¹åŸ·è¡Œè¨“ç·´ä»»å‹™ï¼šå…ˆåŸ·è¡Œ NERL ä»»å‹™ï¼Œå†åŸ·è¡Œ DQN ä»»å‹™
        
        Args:
            training_tasks: è¨“ç·´ä»»å‹™åˆ—è¡¨
            
        Returns:
            dict: åŸ·è¡Œçµæœ
        """
        results = {}
        
        # åˆ†çµ„ä»»å‹™
        nerl_tasks = [task for task in training_tasks if task[0] == 'nerl']
        dqn_tasks = [task for task in training_tasks if task[0] == 'dqn']
        
        # ç¬¬ä¸€æ‰¹ï¼šåŸ·è¡Œ NERL ä»»å‹™
        if nerl_tasks:
            self.print_header(f"ç¬¬ä¸€æ‰¹ï¼šåŸ·è¡Œ {len(nerl_tasks)} å€‹ NERL è¨“ç·´ä»»å‹™", Colors.BLUE)
            nerl_results = self._run_task_group(nerl_tasks, "NERL")
            results.update(nerl_results)
        
        # ç¬¬äºŒæ‰¹ï¼šåŸ·è¡Œ DQN ä»»å‹™
        if dqn_tasks:
            self.print_header(f"ç¬¬äºŒæ‰¹ï¼šåŸ·è¡Œ {len(dqn_tasks)} å€‹ DQN è¨“ç·´ä»»å‹™", Colors.BLUE)
            dqn_results = self._run_task_group(dqn_tasks, "DQN")
            results.update(dqn_results)
        
        return results
    
    
    def run_evaluation_workflow(self, config: Dict, parallel: bool = True) -> Dict[str, bool]:
        """
        åŸ·è¡Œè©•ä¼°å·¥ä½œæµç¨‹
        
        Args:
            config: è©•ä¼°é…ç½®
            parallel: æ˜¯å¦ä¸¦è¡ŒåŸ·è¡Œ
            
        Returns:
            dict: åŸ·è¡Œçµæœ
        """
        self.print_header("é–‹å§‹æ•ˆèƒ½è©•ä¼°", Colors.CYAN)
        
        # æº–å‚™è©•ä¼°ä»»å‹™
        evaluation_tasks = self._prepare_evaluation_tasks(config)
        
        if not evaluation_tasks:
            self.print_warning("æ²’æœ‰å¯åŸ·è¡Œçš„è©•ä¼°ä»»å‹™")
            return {}
        
        results = {}
        self.execution_stats["total_tasks"] += len(evaluation_tasks)
        
        if parallel and len(evaluation_tasks) > 1:
            self.print_info(f"ä¸¦è¡ŒåŸ·è¡Œ {len(evaluation_tasks)} å€‹è©•ä¼°å¯¦é©—...")
            results = self._run_evaluation_parallel(evaluation_tasks)
        else:
            self.print_info("é †åºåŸ·è¡Œæ‰€æœ‰è©•ä¼°å¯¦é©—...")
            results = self._run_evaluation_sequential(evaluation_tasks)
        
        # çµ±è¨ˆçµæœ
        successful = sum(1 for success in results.values() if success)
        self.execution_stats["completed_tasks"] += successful
        self.execution_stats["failed_tasks"] += len(results) - successful
        self.execution_stats["results"]["evaluation"] = results
        
        color = Colors.GREEN if successful == len(results) else Colors.YELLOW
        self.print_header(f"è©•ä¼°å®Œæˆ: {successful}/{len(results)} å€‹å¯¦é©—æˆåŠŸ", color)
        
        return results
    
    def _prepare_evaluation_tasks(self, config: Dict) -> List[Dict]:
        """æº–å‚™è©•ä¼°ä»»å‹™åˆ—è¡¨"""
        tasks = []
        
        # æª¢æŸ¥å¯ç”¨æ§åˆ¶å™¨
        controllers = config.get('controllers', 'auto')
        if controllers == 'auto':
            controllers = self._detect_available_controllers()
        
        if len(controllers) < 2:
            self.print_warning("æ§åˆ¶å™¨æ•¸é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘2å€‹æ§åˆ¶å™¨é€²è¡Œå°æ¯”")
            return []
        
        self.print_info(f"å°‡è©•ä¼°çš„æ§åˆ¶å™¨: {', '.join(controllers)}")
        
        # æº–å‚™ä¸åŒé¡å‹çš„è©•ä¼°å¯¦é©—
        base_config = {
            "ticks": config.get('ticks', 15000),
            "description": config.get('description', 'experiment'),
            "output_dir": config.get('output_dir', None)
        }
        
        seeds = config.get('seeds', [42, 123, 789])
        
        # ç‚ºæ¯å€‹éš¨æ©Ÿç¨®å­å‰µå»ºä»»å‹™
        for i, seed in enumerate(seeds):
            task = base_config.copy()
            task['controllers'] = controllers
            task['seed'] = seed
            task['description'] = f"{base_config['description']}_seed{seed}"
            task['run_name'] = f"å¯¦é©—é‹è¡Œ {i+1}/{len(seeds)} (seed={seed})"
            # å‚³é use_new_windows è¨­ç½®
            task['use_new_windows'] = config.get('use_new_windows', True)
            # å‚³é use_netlogo è¨­ç½®
            task['use_netlogo'] = config.get('use_netlogo', False)
            # å‚³éæ—¥èªŒç´šåˆ¥è¨­ç½®
            task['log_level'] = config.get('log_level', 'INFO')
            tasks.append(task)
        
        return tasks
    
    def _detect_available_controllers(self) -> List[str]:
        """æª¢æ¸¬å¯ç”¨çš„æ§åˆ¶å™¨"""
        available = []
        
        # å‚³çµ±æ§åˆ¶å™¨ç¸½æ˜¯å¯ç”¨
        available.extend(["time_based", "queue_based"])
        
        # æª¢æŸ¥AIæ§åˆ¶å™¨çš„æ¨¡å‹æ–‡ä»¶
        ai_controllers = ["dqn_step", "dqn_global", "nerl_step", "nerl_global"]
        for controller in ai_controllers:
            model_path = self.models_dir / f"{controller}.pth"
            if model_path.exists():
                available.append(controller)
        
        return available
    
    def _run_evaluation_parallel(self, evaluation_tasks: List[Dict]) -> Dict[str, bool]:
        """ä¸¦è¡ŒåŸ·è¡Œè©•ä¼°ä»»å‹™"""
        results = {}
        max_workers = min(3, len(evaluation_tasks))
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(self._run_single_evaluation, task): task
                for task in evaluation_tasks
            }
            
            for i, future in enumerate(as_completed(future_to_task)):
                task = future_to_task[future]
                task_key = task["description"]
                
                try:
                    success, output = future.result()
                    results[task_key] = success
                    
                    if success:
                        self.print_success(f"âœ“ {task['run_name']} å®Œæˆ")
                    else:
                        self.print_error(f"âœ— {task['run_name']} å¤±æ•—")
                        
                except Exception as e:
                    self.print_error(f"âœ— {task['run_name']} ç•°å¸¸: {e}")
                    results[task_key] = False
                
                self.print_progress(i + 1, len(evaluation_tasks), f"å·²å®Œæˆ {i + 1}/{len(evaluation_tasks)} å€‹å¯¦é©—")
        
        return results
    
    def _run_evaluation_sequential(self, evaluation_tasks: List[Dict]) -> Dict[str, bool]:
        """é †åºåŸ·è¡Œè©•ä¼°ä»»å‹™"""
        results = {}
        
        for i, task in enumerate(evaluation_tasks):
            self.print_progress(i, len(evaluation_tasks), f"æ­£åœ¨åŸ·è¡Œ {task['run_name']}")
            
            success, output = self._run_single_evaluation(task)
            results[task["description"]] = success
            
            if success:
                self.print_success(f"âœ“ {task['run_name']} å®Œæˆ")
            else:
                self.print_error(f"âœ— {task['run_name']} å¤±æ•—")
            
            self.print_progress(i + 1, len(evaluation_tasks), f"å·²å®Œæˆ {i + 1}/{len(evaluation_tasks)} å€‹å¯¦é©—")
        
        return results
    
    def _run_single_evaluation(self, task: Dict) -> Tuple[bool, str]:
        """åŸ·è¡Œå–®å€‹è©•ä¼°ä»»å‹™"""
        controllers_str = " ".join(task["controllers"])
        cmd = f"python evaluate.py --controllers {controllers_str}"
        cmd += f" --ticks {task['ticks']}"
        cmd += f" --seed {task['seed']}"
        cmd += f" --description \"{task['description']}\""
        
        if task.get('output_dir'):
            cmd += f" --output \"{task['output_dir']}\""
        
        # æ·»åŠ  NetLogo åƒæ•¸ï¼ˆå¦‚æœä»»å‹™é…ç½®ä¸­æŒ‡å®šï¼‰
        if task.get('use_netlogo', False):
            cmd += " --netlogo"
        
        # æ·»åŠ æ—¥èªŒç´šåˆ¥åƒæ•¸
        log_level = task.get('log_level', 'INFO')
        cmd += f" --log_level {log_level}"
        
        timeout = max(1200, task['ticks'] // 10)
        window_title = f"è©•ä¼° {task['run_name']}"
        
        # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨æ–°è¦–çª—ï¼ˆå¾ä»»å‹™é…ç½®ä¸­ç²å–ï¼Œé è¨­ç‚ºTrueï¼‰
        use_new_window = task.get('use_new_windows', True)
        
        # åŸ·è¡Œè©•ä¼°
        return self.run_command(cmd, f"è©•ä¼°å¯¦é©—: {task['description']}", timeout,
                              open_new_window=use_new_window,
                              window_title=window_title)
    
    def run_analysis_workflow(self, config: Dict = None, specific_eval_dir: str = None) -> Dict[str, bool]:
        """
        åŸ·è¡Œæ•¸æ“šåˆ†æå·¥ä½œæµç¨‹
        
        Args:
            config: åˆ†æé…ç½®
            specific_eval_dir: ç‰¹å®šçš„è©•ä¼°ç›®éŒ„åç¨±ï¼ˆå¦‚æœæä¾›ï¼Œåªåˆ†æé€™å€‹ç›®éŒ„ï¼‰
            
        Returns:
            dict: åŸ·è¡Œçµæœ
        """
        self.print_header("é–‹å§‹æ•¸æ“šåˆ†æèˆ‡åœ–è¡¨ç”Ÿæˆ", Colors.YELLOW)
        
        # æ‰¾åˆ°è©•ä¼°çµæœç›®éŒ„
        if specific_eval_dir:
            # åªåˆ†æç‰¹å®šç›®éŒ„
            eval_path = self.results_dir / "evaluations" / specific_eval_dir
            if eval_path.exists():
                eval_dirs = [eval_path]
            else:
                self.print_error(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„è©•ä¼°ç›®éŒ„: {specific_eval_dir}")
                return {}
        else:
            # åˆ†ææ‰€æœ‰ç›®éŒ„
            eval_dirs = list(self.results_dir.glob("evaluations/EVAL_*"))
        
        if not eval_dirs:
            self.print_warning("æ²’æœ‰æ‰¾åˆ°è©•ä¼°çµæœç›®éŒ„")
            return {}
        
        results = {}
        self.execution_stats["total_tasks"] += len(eval_dirs)
        
        # ç‚ºæ¯å€‹çµæœç›®éŒ„ç”Ÿæˆåœ–è¡¨
        for i, eval_dir in enumerate(eval_dirs):
            self.print_progress(i, len(eval_dirs), f"æ­£åœ¨åˆ†æ {eval_dir.name}")
            
            success, output = self._generate_charts_for_result(eval_dir, config)
            results[eval_dir.name] = success
            
            if success:
                self.print_success(f"âœ“ {eval_dir.name} åœ–è¡¨ç”Ÿæˆå®Œæˆ")
            else:
                self.print_error(f"âœ— {eval_dir.name} åœ–è¡¨ç”Ÿæˆå¤±æ•—")
            
            self.print_progress(i + 1, len(eval_dirs), f"å·²å®Œæˆ {i + 1}/{len(eval_dirs)} å€‹åˆ†æ")
        
        # çµ±è¨ˆçµæœ
        successful = sum(1 for success in results.values() if success)
        self.execution_stats["completed_tasks"] += successful
        self.execution_stats["failed_tasks"] += len(results) - successful
        self.execution_stats["results"]["analysis"] = results
        
        color = Colors.GREEN if successful == len(results) else Colors.YELLOW
        self.print_header(f"åˆ†æå®Œæˆ: {successful}/{len(results)} å€‹åœ–è¡¨æˆåŠŸ", color)
        
        return results
    
    def _generate_charts_for_result(self, eval_dir: Path, config: Dict = None) -> Tuple[bool, str]:
        """ç‚ºè©•ä¼°çµæœç”Ÿæˆåœ–è¡¨"""
        cmd = f"python visualization_generator.py \"{eval_dir}\""
        
        if config:
            chart_types = config.get('types', 'all')
            if isinstance(chart_types, list):
                chart_types = ','.join(chart_types)
            cmd += f" --chart {chart_types}"
        else:
            cmd += " --chart all"
        
        return self.run_command(cmd, f"ç”Ÿæˆåœ–è¡¨: {eval_dir.name}", timeout=180)
    
    def run_complete_workflow(self, config: Dict, parallel: bool = True) -> Dict:
        """
        åŸ·è¡Œå®Œæ•´å¯¦é©—å·¥ä½œæµç¨‹
        
        Args:
            config: å®Œæ•´å¯¦é©—é…ç½®
            parallel: æ˜¯å¦ä¸¦è¡ŒåŸ·è¡Œ
            
        Returns:
            dict: åŸ·è¡Œçµæœ
        """
        self.print_header("é–‹å§‹å®Œæ•´å¯¦é©—æµç¨‹", Colors.GREEN)
        self.execution_stats["start_time"] = datetime.now()
        
        complete_results = {}
        
        # éšæ®µ1ï¼šæ¨¡å‹è¨“ç·´
        if 'training' in config:
            self.print_info("éšæ®µ1ï¼šAIæ¨¡å‹è¨“ç·´")
            training_results = self.run_training_workflow(config['training'], parallel)
            complete_results['training'] = training_results
        
        # éšæ®µ2ï¼šæ•ˆèƒ½è©•ä¼°
        if 'evaluation' in config:
            self.print_info("éšæ®µ2ï¼šæ•ˆèƒ½è©•ä¼°")
            evaluation_results = self.run_evaluation_workflow(config['evaluation'], parallel)
            complete_results['evaluation'] = evaluation_results
        
        # éšæ®µ3ï¼šæ•¸æ“šåˆ†æ
        if 'analysis' in config or config.get('auto_analysis', True):
            self.print_info("éšæ®µ3ï¼šæ•¸æ“šåˆ†æèˆ‡åœ–è¡¨")
            analysis_config = config.get('analysis', config.get('charts', {}))
            analysis_results = self.run_analysis_workflow(analysis_config)
            complete_results['analysis'] = analysis_results
        
        self.execution_stats["end_time"] = datetime.now()
        
        # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
        self._show_final_statistics(complete_results)
        
        return complete_results
    
    def _show_final_statistics(self, results: Dict):
        """é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆçµæœ"""
        self.print_header("å¯¦é©—å®Œæˆçµ±è¨ˆ", Colors.GREEN)
        
        total_time = None
        if self.execution_stats["start_time"] and self.execution_stats["end_time"]:
            total_time = (self.execution_stats["end_time"] - self.execution_stats["start_time"]).total_seconds() / 60
        
        print(f"{Colors.WHITE}åŸ·è¡Œçµ±è¨ˆ:{Colors.END}")
        if total_time:
            print(f"  ç¸½è€—æ™‚: {total_time:.1f} åˆ†é˜")
        print(f"  ç¸½ä»»å‹™æ•¸: {self.execution_stats['total_tasks']}")
        print(f"  æˆåŠŸä»»å‹™: {self.execution_stats['completed_tasks']}")
        print(f"  å¤±æ•—ä»»å‹™: {self.execution_stats['failed_tasks']}")
        
        success_rate = (self.execution_stats['completed_tasks'] / max(1, self.execution_stats['total_tasks'])) * 100
        color = Colors.GREEN if success_rate >= 80 else Colors.YELLOW if success_rate >= 50 else Colors.RED
        print(f"  {color}æˆåŠŸç‡: {success_rate:.1f}%{Colors.END}")
        
        # è©³ç´°çµæœ
        for stage, stage_results in results.items():
            if stage_results:
                successful = sum(1 for success in stage_results.values() if success)
                total = len(stage_results)
                stage_rate = (successful / total) * 100 if total > 0 else 0
                stage_color = Colors.GREEN if stage_rate >= 80 else Colors.YELLOW if stage_rate >= 50 else Colors.RED
                
                stage_name = {"training": "æ¨¡å‹è¨“ç·´", "evaluation": "æ•ˆèƒ½è©•ä¼°", "analysis": "æ•¸æ“šåˆ†æ"}.get(stage, stage)
                print(f"  {stage_color}{stage_name}: {successful}/{total} ({stage_rate:.1f}%){Colors.END}")
        
        # é¡¯ç¤ºçµæœä½ç½®
        print(f"\n{Colors.WHITE}çµæœæ–‡ä»¶ä½ç½®:{Colors.END}")
        
        if 'evaluation' in results:
            eval_dirs = list(self.results_dir.glob("evaluations/EVAL_*"))
            if eval_dirs:
                latest_eval = max(eval_dirs, key=lambda x: x.stat().st_mtime)
                print(f"  ğŸ“Š æœ€æ–°è©•ä¼°çµæœ: {latest_eval}")
        
        if 'analysis' in results:
            print(f"  ğŸ“ˆ åœ–è¡¨æ–‡ä»¶: result/evaluations/*/charts/")
        
        print(f"\n{Colors.CYAN}ğŸ‰ å¯¦é©—æµç¨‹å®Œæˆï¼{Colors.END}")
    
    def get_execution_stats(self) -> Dict:
        """ç²å–åŸ·è¡Œçµ±è¨ˆè³‡è¨Š"""
        return self.execution_stats.copy()