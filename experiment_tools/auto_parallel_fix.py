"""
è‡ªå‹•ä¿®å¾©ä¸¦è¡ŒåŸ·è¡Œå•é¡Œçš„æ¨¡çµ„
======================

è‡ªå‹•æ•´åˆåˆ°å¯¦é©—è…³æœ¬ä¸­ï¼Œç„¡éœ€æ‰‹å‹•æ“ä½œ
"""

import os
import re
import shutil
from pathlib import Path
from datetime import datetime

class AutoParallelFixer:
    """è‡ªå‹•ä¿®å¾©ä¸¦è¡Œå•é¡Œçš„å·¥å…·é¡"""
    
    def __init__(self):
        self.fixed_files = []
        self.backup_dir = Path("backups") / datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def check_and_fix(self):
        """æª¢æŸ¥ä¸¦è‡ªå‹•ä¿®å¾©ä¸¦è¡Œå•é¡Œ"""
        print("\nğŸ” æª¢æŸ¥ä¸¦è¡ŒåŸ·è¡Œç’°å¢ƒ...")
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“ä¿®å¾©é
        if self._is_already_fixed():
            print("âœ… ç³»çµ±å·²ç¶“æ”¯æ´ä¸¦è¡ŒåŸ·è¡Œ")
            return True
        
        print("âš ï¸  æª¢æ¸¬åˆ° CSV è¡çªå•é¡Œï¼Œé–‹å§‹è‡ªå‹•ä¿®å¾©...")
        
        # å‰µå»ºå‚™ä»½ç›®éŒ„
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿®å¾©å„å€‹æª”æ¡ˆ
        success = True
        success &= self._fix_warehouse()
        success &= self._fix_generator()
        success &= self._fix_netlogo()
        
        if success:
            print("âœ… ä¸¦è¡Œç’°å¢ƒä¿®å¾©å®Œæˆï¼")
            return True
        else:
            print("âŒ ä¿®å¾©å¤±æ•—ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥")
            return False
    
    def _is_already_fixed(self):
        """æª¢æŸ¥æ˜¯å¦å·²ç¶“ä¿®å¾©é"""
        warehouse_path = Path("world/warehouse.py")
        if warehouse_path.exists():
            with open(warehouse_path, 'r', encoding='utf-8') as f:
                content = f.read()
                return "os.getpid()" in content
        return False
    
    def _backup_file(self, file_path):
        """å‚™ä»½æª”æ¡ˆ"""
        if file_path.exists():
            backup_path = self.backup_dir / file_path.name
            shutil.copy2(file_path, backup_path)
            return backup_path
        return None
    
    def _fix_warehouse(self):
        """ä¿®å¾© warehouse.py"""
        file_path = Path("world/warehouse.py")
        if not file_path.exists():
            return False
        
        # å‚™ä»½
        self._backup_file(file_path)
        
        # è®€å–å…§å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ·»åŠ  import osï¼ˆå¦‚æœéœ€è¦ï¼‰
        if "import os" not in content.split('\n')[:50]:
            import_match = re.search(r'(import .+\n)+', content)
            if import_match:
                insert_pos = import_match.end()
                content = content[:insert_pos] + "import os\n" + content[insert_pos:]
        
        # ä¿®æ”¹ CSV è·¯å¾‘
        pattern = r'file_path = PARENT_DIRECTORY \+ "/data/input/assign_order\.csv"'
        replacement = 'file_path = PARENT_DIRECTORY + f"/data/input/assign_order_{os.getpid()}.csv"'
        content = re.sub(pattern, replacement, content)
        
        # å¯«å›
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.fixed_files.append(str(file_path))
        return True
    
    def _fix_generator(self):
        """ä¿®å¾© warehouse_generator.py"""
        file_path = Path("lib/generator/warehouse_generator.py")
        if not file_path.exists():
            return True  # ä¸æ˜¯å¿…é ˆçš„æª”æ¡ˆ
        
        # å‚™ä»½
        self._backup_file(file_path)
        
        # è®€å–å…§å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä¿®æ”¹ CSV è·¯å¾‘
        pattern = r'file_path = PARENT_DIRECTORY \+ "/data/input/assign_order\.csv"'
        replacement = 'file_path = PARENT_DIRECTORY + f"/data/input/assign_order_{os.getpid()}.csv"'
        content = re.sub(pattern, replacement, content)
        
        # å¯«å›
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.fixed_files.append(str(file_path))
        return True
    
    def _fix_netlogo(self):
        """ä¿®å¾© netlogo.py"""
        file_path = Path("netlogo.py")
        if not file_path.exists():
            return False
        
        # å‚™ä»½
        self._backup_file(file_path)
        
        # è®€å–å…§å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä¿®æ”¹ CSV è·¯å¾‘
        pattern = r'assignment_path = PARENT_DIRECTORY \+ "/data/input/assign_order\.csv"'
        replacement = 'assignment_path = PARENT_DIRECTORY + f"/data/input/assign_order_{os.getpid()}.csv"'
        content = re.sub(pattern, replacement, content)
        
        # å¯«å›
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.fixed_files.append(str(file_path))
        return True
    
    def cleanup_temp_csv(self):
        """æ¸…ç†è‡¨æ™‚ CSV æª”æ¡ˆ"""
        csv_dir = Path("data/input")
        if csv_dir.exists():
            temp_files = list(csv_dir.glob("assign_order_*.csv"))
            for f in temp_files:
                if f.name != "assign_order.csv":
                    try:
                        f.unlink()
                    except:
                        pass
    
    def restore_backups(self):
        """é‚„åŸå‚™ä»½ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        if self.backup_dir.exists():
            print(f"å‚™ä»½æª”æ¡ˆä½æ–¼: {self.backup_dir}")
            # é€™è£¡ä¸è‡ªå‹•é‚„åŸï¼Œè®“ä½¿ç”¨è€…æ‰‹å‹•è™•ç†


# å–®ä¾‹æ¨¡å¼ï¼Œç¢ºä¿åªåˆå§‹åŒ–ä¸€æ¬¡
_fixer_instance = None

def get_fixer():
    """ç²å–ä¿®å¾©å™¨å¯¦ä¾‹"""
    global _fixer_instance
    if _fixer_instance is None:
        _fixer_instance = AutoParallelFixer()
    return _fixer_instance