# Abstract

Traffic congestion in high-density Robotic Mobile Fulfillment Systems (RMFS) critically bottlenecks system throughput and energy efficiency. To address this, this study develops a self-adaptive traffic control strategy using Neuroevolution Reinforcement Learning (NERL). On a high-fidelity simulator, this research systematically tests various NERL training configurations and compares them against rule-based and Deep Q-Network (DQN) baselines.

The results show that optimal training performance does not guarantee generalization due to overfitting. The final validation identifies a NERL configuration—trained with step-rewards, low exploration, and long evaluation duration—that achieves the best-balanced performance. It delivers a top-tier order completion rate (91.27%) with superior energy efficiency (33 EU/Order). This finding highlights the importance of a robust training framework for DRL's practical application and provides an effective multi-objective optimization solution for intelligent warehouses.

**Keywords**: Automated Warehouse, Robotic Mobile Fulfillment System (RMFS), Traffic Control, Deep Reinforcement Learning (DRL), Neuroevolution, Multi-objective Optimization 