# 5.2 研究貢獻

本研究在理論、方法與實務應用層面，為自動化倉儲的交通控制領域帶來了數點具體貢獻。在理論層面，本論文最核心的貢獻之一，是透過嚴謹的對照實驗，系統性地揭示了深度強化學習模型在訓練效能與最終泛化能力之間的潛在鴻溝。研究明確指出，在訓練階段表現最優的策略（如全局獎勵驅動的複雜策略），在更長、更通用的驗證環境中可能因過擬合而失效。此發現為 DRL 領域提供了一個重要的實證案例，強調在評估模型時，必須將標準化的泛化能力測試作為最終的黃金標準，而非僅僅依賴訓練過程中的指標。

在方法論上，本研究成功地將神經演化強化學習 (NERL) 應用於複雜的 RMFS 交通控制問題，並通過實驗驗證，找到了一套能夠催生出兼具高產出與高能效的均衡型策略的訓練配置，即步階獎勵、低探索性與長時評估的組合。此成果不僅為 NERL 這種混合式 DRL 方法在物流自動化領域的應用提供了成功案例，更為未來研究者在設計 DRL 系統時，如何在「探索的廣度」與「學習的穩定性」之間進行權衡，提供了具體的實驗依據與啟示。

基於此方法論，本研究在實務應用層面也取得了顯著成果。我們所提出的 F 組模型 (NERL-Step, 低探索, 8000 Ticks) 在所有測試控制器中，展現了最佳的綜合性能，尤其是在能效比方面顯著優於傳統基線與標準 DQN 模型。這為倉儲營運商在追求提升自動化系統吞吐量的同時，如何有效控制日益增長的能源成本與碳足跡，提供了一個具備高度潛在應用價值的先進技術方案。

最後，本研究所有成果的取得，皆奠基於我們從頭建構的可擴展、高擬真度 RMFS 模擬平台。該平台不僅為本論文的各項實驗提供了堅實的基礎，其模組化的設計也使其具備良好的可擴展性，可供未來研究者用於測試更先進的演算法、不同的倉儲佈局或更複雜的任務調度策略，從而構成了推動整個領域發展的基礎設施貢獻。 