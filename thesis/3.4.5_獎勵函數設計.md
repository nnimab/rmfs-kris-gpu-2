# 3.4.5 獎勵函數設計

獎勵函數 $R(s, a, s')$ 是連接 DRL 智能體動作與其最終學習目標的關鍵橋樑。它通過一個純量回饋信號來評估智能體在狀態 $s$ 採取動作 $a$ 後轉移到狀態 $s'$ 的優劣。在本研究中，為了系統性地探究不同學習信號對模型性能與行為的影響，我們設計並實現了兩種性質截然不同的獎勵模式。這兩種模式旨在權衡即時回饋的指導性與最終目標的全局性，並分別應用於不同的 DRL 控制器訓練中（詳見 **3.6.1 節**）。

### 1. 步階獎勵 (Step Reward)

步階獎勵模式旨在為智能體提供一個密集的、即時的回饋信號，主要用於指導 DQN 控制器的學習。在每個決策間隔 $T_{\text{decision}}$ 結束時，系統會根據該時間段內交叉路口的局部觀測指標，計算一個綜合獎勵值 $R_{\text{step}}$。這種高頻率的回饋有助於智能體快速學習到基礎的交通控制啟發式規則。

$R_{\text{step}}$ 由以下四個加權分量的線性組合而成：

$$
R_{\text{step}} = w_{\text{critical}} \cdot (R_{\text{flow}} - P_{\text{wait}} - P_{\text{energy}} - P_{\text{switch}})
$$

*   **流量獎勵 ($R_{\text{flow}}$)**: 正向獎勵，鼓勵控制器最大化通行效率。
    $$
    R_{\text{flow}} = w_{\text{flow}} \times N_{\text{passed}}
    $$
    其中 $N_{\text{passed}}$ 是在決策間隔內成功通過交叉口的機器人總數。

*   **等待時間懲罰 ($P_{\text{wait}}$)**: 負向獎勵，懲罰因排隊而累積的總等待時間。
    $$
    P_{\text{wait}} = w_{\text{wait}} \times T_{\text{cumulative\_wait}}
    $$

*   **能源消耗懲罰 ($P_{\text{energy}}$)**: 負向獎勵，懲罰因等待和加減速造成的估算能源消耗。
    $$
    P_{\text{energy}} = w_{\text{energy}} \times E_{\text{consumed}}
    $$

*   **相位切換懲罰 ($P_{\text{switch}}$)**: 一個固定的負向獎勵，僅在號誌相位發生切換時觸發，旨在避免過於頻繁、無效的切換。

此外，$w_{\text{critical}}$ 是一個**關鍵路口加權係數**。對於靠近揀貨站等系統瓶頸的交叉路口，該係數會大於 1，從而放大其獎勵信號，促使智能體優先學習管理這些關鍵節點。

### 2. 全局獎勵 (Global Reward)

與步階獎勵不同，全局獎勵模式提供一個稀疏的、延遲的回饋信號，是 NERL 方法的核心評估指標。在這種模式下，智能體在整個評估回合（Episode）中不會收到任何即時獎勵。只有在回合結束時，系統才會根據整個倉儲的最終宏觀性能指標，計算一個單一的獎勵值 $R_{\text{global}}$，該值也作為 NERL 中的**適應度分數**。

這種模式迫使智能體學習一系列能夠對系統長期、全局目標（而非局部指標）產生積極影響的複雜協同行為。$R_{\text{global}}$ 由以下幾個核心指標的加權組合而成：

$$
R_{\text{global}} = S_{\text{order}} - C_{\text{time}} - C_{\text{energy}} - P_{\text{spillback}}
$$

*   **訂單完成分數 ($S_{\text{order}}$)**: 主要的正向獎勵，基於在規定時間內完成的訂單數量。
    $$
    S_{\text{order}} = w_{\text{order}} \times N_{\text{completed\_orders}}
    $$

*   **總時間成本 ($C_{\text{time}}$)**: 負向獎勵，懲罰所有訂單從生成到完成所花費的總時間。
    $$
    C_{\text{time}} = w_{\text{time}} \times T_{\text{total\_order\_time}}
    $$

*   **總能源成本 ($C_{\text{energy}}$)**: 負向獎勵，懲罰系統在運行期間的總估算能耗。
    $$
    C_{\text{energy}} = w_{\text{energy\_global}} \times E_{\text{total}}
    $$

*   **回堵懲罰 ($P_{\text{spillback}}$)**: 一個巨大的負向懲罰。如果在評估期間發生了導致系統死鎖的嚴重回堵，則施加此懲罰，以確保智能體學會避免災難性的策略。 