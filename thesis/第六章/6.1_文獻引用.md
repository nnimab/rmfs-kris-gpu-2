# 6.1 文獻引用

[1] eMarketer. (2024, February). *Worldwide ecommerce will account for over 20% of retail sales in 2024*. https://www.emarketer.com/content/ecommerce-account-more-than-20--of-worldwide-retail-sales-despite-slowdown

[2] DHL. (2024). *Sustainability trends in logistics for 2024*. DHL. https://www.dhl.com/discover/en-global/logistics-advice/sustainability-and-green-logistics/sustainability-trends-in-logistics

[3] PwC. (2023). *The EU CBAM: Implications for supply chains*. PwC. https://www.pwc.com/gx/en/services/tax/esg-tax/cbam-supply-chain-imperatives.html

[4] Mousavi, S. S., Fathollahi-Fard, A. M., & Hajiaghaei-Keshteli, M. (2024). Deep reinforcement learning driven cost minimization for batch-picking in robotic mobile fulfillment systems. *Expert Systems with Applications*, *254*, 124568.

[5] Song, L., Li, K., Yang, K., Liu, P., & Yang, K. (2025). Towards energy-efficient Robotic Mobile Fulfillment System: Hybrid traffic control for automated guided vehicles. *Applied Soft Computing*, *173*, 113452.

[6] Wurman, P., D'Andrea, R., & Mountz, M. (2008). Coordinating hundreds of cooperative, autonomous vehicles in warehouses. *AI Magazine*, *29*(1), 9-20.

[7] Guizzo, E. (2012, March 19). *Amazon acquires Kiva Systems for $775 million*. IEEE Spectrum. Benavides-Robles, M.T., et al., Robotic Mobile Fulfillment System: A Systematic Review.

[8] Merschformann, M., et al. (2019). Decision rules for robotic mobile fulfillment systems. *Operations Research Perspectives*, *6*, 100128.

[9] Stern, R. (2019). Multi-agent path finding–an overview. In *Artificial Intelligence: 5th RAAI Summer School, Tutorial Lectures* (pp. 96-115).

[10] Li, X., Hua, G., Huang, A., Sheu, J. B., Cheng, T. C. E., & Huang, F. (2020). Storage assignment policy with awareness of energy consumption in the Kiva mobile fulfilment system. *Transportation Research Part E: Logistics and Transportation Review*, *144*, 102158.

[11] Luo, L., Zhao, N., Zhu, Y., & Sun, Y. (2023). A* guiding DQN algorithm for automated guided vehicle pathfinding problem of robotic mobile fulfillment systems. *Computers & Industrial Engineering*, *178*, 109112.

[12] Zhou, Y., Guo, K., Yu, C., & Zhang, Z. (2024). Optimization of multi-echelon spare parts inventory systems using multi-agent deep reinforcement learning. *Applied Mathematics and Computation*, *469*, 128532.

[13] Dunne, M. C., & Potts, R. B. (1964). Algorithm for traffic control. *Operations Research*, *12*(6), 870-881.

[14] Teja, V. A., Viswanath, D. V. K., & Krishna, K. M. (2009, February 21-25). A mixed autonomy coordination methodology for multi-robotic traffic control. In *2008 IEEE International Conference on Robotics and Biomimetics* (pp. 1391-1396).

[15] Ross, D., Sandys, R., & Schlaefli, J. (1971). A computer control scheme for critical-intersection control in an urban network. *Transportation Science*, *5*(2), 141-160.

[16] Sutton, R. S., & Barto, A. G. (2018). *Reinforcement learning: An introduction*. MIT press.

[17] Zheng, G., et al. (2019, November 3-7). Learning phase competition for traffic signal control. In *Proceedings of the 28th ACM International Conference on Information and Knowledge Management* (pp. 1653-1662).

[18] Cao, K., Wang, L., Zhang, S., Duan, L., Jiang, G., Sfarra, S., Zhang, H., & Jung, H. (2024). Optimization control of adaptive traffic signal with deep reinforcement learning. *Electronics*, *13*(1), 198.

[19] Zhu, Y., Cai, M., Schwarz, C., Li, J., & Xiao, S. (2022). Intelligent traffic light via policy-based deep reinforcement learning. *International Journal of Intelligent Transportation Systems Research*, *20*(3), 734-744.

[20] Angela, J., Sujana, J., & Namasivaayam, L. (2024, August 22-23). Pressure, queue, and average speed - based multi-agent DQN for optimizing traffic signal control. *2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS)* (pp. 1-6).

[21] Chen, Y. F., et al. (2017, May 29-June 3). Decentralized non-communicating multiagent collision avoidance with deep reinforcement learning. In *2017 IEEE International Conference on Robotics and Automation (ICRA)*. IEEE.

[22] Ma, Z., Luo, Y., & Ma, H. (2021, May 30-June 5). Distributed heuristic multi-agent path finding with communication. In *2021 IEEE International Conference on Robotics and Automation (ICRA)*.

[23] Heidrich-Meisner, V., & Igel, C. (2009). Neuroevolution strategies for episodic reinforcement learning. *Journal of Algorithms*, *64*(4), 152-168.

[24] AbuZekry, A. (2019). Comparative study of NeuroEvolution algorithms in reinforcement learning for self-driving cars. *European Journal of Engineering Science and Technology*.

[25]Salimans, T., Ho, J., Chen, X., Sidor, S., & Sutskever, I. (2017). Evolution strategies as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864.

[26]Yuan, R., Dou, J., Li, J., Wang, W., & Jiang, Y. (2023). Multi-robot task allocation in e-commerce RMFS based on deep reinforcement learning.. Mathematical biosciences and engineering : MBE, 20 2, 1903-1918 .

[27]Zhou, X., Shi, X., Chu, W., Jiang, J., Zhang, L., & Deng, F. (2024). Learning to Solve Multi-AGV Scheduling Problem with Pod Repositioning Optimization in RMFS. 2024 IEEE International Conference on Industrial Technology (ICIT), 1-8.

[28] Zou, B., Xu, X., & De Koster, R. (2018). Evaluating battery charging and swapping strategies in a robotic mobile fulfillment system. *European Journal of Operational Research*, *267*(2), 733-753. 